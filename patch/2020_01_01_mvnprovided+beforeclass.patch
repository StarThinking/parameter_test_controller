diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/pom.xml /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/pom.xml
--- ./hadoop-hdfs-project/hadoop-hdfs/pom.xml	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/pom.xml	2020-01-01 13:19:04.714299893 -0600
@@ -36,6 +36,7 @@
   </properties>
 
   <dependencies>
+
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-annotations</artifactId>
@@ -228,7 +229,8 @@
           <properties>
             <property>
               <name>listener</name>
-              <value>org.apache.hadoop.test.TimedOutTestsListener</value>
+              <value>MyRunListener</value>
+              <!--<value>org.apache.hadoop.test.TimedOutTestsListener</value>-->
             </property>
           </properties>
         </configuration>
@@ -421,9 +423,24 @@
           </filesets>
         </configuration>
       </plugin>
+<!--
+  <plugin>
+    <groupId>org.apache.maven.plugins</groupId>
+    <artifactId>maven-surefire-plugin</artifactId>
+    <version>3.0.0-M4</version>
+    <configuration>
+      <properties>
+        <property>
+          <name>listener</name>
+          <value>MyRunListener</value>
+        </property>
+      </properties>
+    </configuration>
+  </plugin>
+-->
+
     </plugins>
   </build>
-
   <profiles>
     <!-- profile that starts ApacheDS KDC server -->
     <profile>
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java	2020-01-01 13:19:04.654298947 -0600
@@ -59,6 +59,9 @@
 import java.util.HashMap;
 import java.util.Map;
 
+// msx
+import java.io.*;
+
 /**
  * The JournalNode is a daemon which allows namenodes using
  * the QuorumJournalManager to log and retrieve edits stored
@@ -147,10 +150,95 @@
     return getOrCreateJournal(jid, nameServiceId, StartupOption.REGULAR);
   }
 
+  // msx
+  public static String parameterReconfig = ""; // just for value check during stop
+  public static int componentHasStopped = 0; // reset at the beginning of each Test
+  public static int restartPerformed = 0; // reset at the beginning of each Test
+  private static Object hasStoppedLock = new Object();
+  private static Object restartPerformedLock = new Object();
+  private static String controllerRootDir = "/root/parameter_test_controller/";
+  static {
+      try {
+        BufferedReader reader = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/componentHasStopped")));
+        String str = reader.readLine();
+        componentHasStopped = Integer.valueOf(str);
+        LOG.info("[msx-restart] componentHasStopped = " + componentHasStopped);
+        reader.close();
+      } catch(Exception e) {
+          e.printStackTrace();
+      }
+  }
+
+  private void recordComponentStopped() {
+      synchronized(hasStoppedLock) {
+          componentHasStopped = 1;
+      }
+  }
+
+  public void performReconfig(String component) throws Exception {
+    BufferedReader reader0 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/parameter")));
+    BufferedReader reader1 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/reconfig_mode")));
+    BufferedReader reader2 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/v1")));
+    BufferedReader reader3 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/v2")));
+    BufferedReader reader4 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/reconfig_component")));
+    String parameter, reconfigMode, v1, v2, reconfigComponent;
+    parameter = reconfigMode = v1 = v2 = reconfigComponent = "";
+    parameter = reader0.readLine();
+    reconfigMode = reader1.readLine();
+    v1 = reader2.readLine();
+    v2 = reader3.readLine();
+    reconfigComponent = reader4.readLine();
+    parameterReconfig = parameter; // global
+    reader0.close();
+    reader1.close();
+    reader2.close();
+    reader3.close();
+    reader4.close();
+    if (reconfigMode.equals("none")) {
+        LOG.info("[msx-restart] " + component + " init, reconfigMode is none, do nothing");
+    } else if (reconfigMode.equals("v1v1")) {
+        if (v1.equals(""))
+            System.exit(1);
+        this.getConf().set(parameter, v1);
+        LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v1=" + v1);
+    } else if (reconfigMode.equals("v2v2")) {
+        if (v2.equals(""))
+            System.exit(1);
+        this.getConf().set(parameter, v2);
+        LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v2=" + v2);
+    } else if (reconfigMode.equals("v1v2")) {
+        if (v1.equals("") || v2.equals(""))
+            System.exit(1);
+        synchronized(hasStoppedLock) {
+            synchronized(restartPerformedLock) {
+                if (reconfigComponent.equals(component) && restartPerformed == 0 && componentHasStopped == 1) {
+                    this.getConf().set(parameter, v2);
+                    LOG.info("[msx-restart] RECONFIG POINT!! " + component + " init, parameter=" + parameter
+                            + " reconfigMode=" + reconfigMode + " parameter=v2=" + v2);
+                    restartPerformed = 1;
+                } else {
+                    this.getConf().set(parameter, v1);
+                    LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v1=" + v1);
+                }
+            }
+        }
+    } else {
+        LOG.info("[msx-restart] ERROR!!!");
+    }
+  }
+
   @Override
   public void setConf(Configuration conf) {
+    LOG.info("[msx-restart] JournalNode setConf conf");
     this.conf = conf;
 
+    // msx
+    try {
+      performReconfig("JournalNode");
+    } catch (Exception e) {
+        e.printStackTrace();
+    }
+
     String journalNodeDir = null;
     Collection<String> nameserviceIds;
 
@@ -210,6 +298,7 @@
    * Start listening for edits via RPC.
    */
   public void start() throws IOException {
+    LOG.info("[msx-restart] JournalNode start");
     Preconditions.checkState(!isStarted(), "JN already running");
 
     try {
@@ -266,6 +355,10 @@
    * should indicate an error)
    */
   public void stop(int rc) {
+    Configuration conf = this.getConf();
+    LOG.info("[msx-restart] JournalNode stop, double check before stop, " + parameterReconfig + " = " + conf.get(parameterReconfig));
+    recordComponentStopped();
+
     this.resultCode = rc;
 
     for (JournalNodeSyncer jSyncer : journalSyncersById.values()) {
@@ -312,6 +405,7 @@
   }
   
   public void stopAndJoin(int rc) throws InterruptedException {
+    //System.out.println("[msx-restart] JournalNode stop");
     stop(rc);
     join();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java	2020-01-01 13:19:04.658299010 -0600
@@ -228,6 +228,9 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+// msx
+import java.io.*;
+
 /**********************************************************
  * DataNode is a class (and program) that stores a set of
  * blocks for a DFS deployment.  A single deployment can
@@ -412,6 +415,83 @@
 
   private ScheduledThreadPoolExecutor metricsLoggerTimer;
 
+  // msx
+  public static String parameterReconfig = ""; // just for value check during stop
+  public static int componentHasStopped = 0; // reset at the beginning of each Test
+  public static int restartPerformed = 0; // reset at the beginning of each Test
+  private static Object hasStoppedLock = new Object();
+  private static Object restartPerformedLock = new Object();
+  private static String controllerRootDir = "/root/parameter_test_controller/";
+  static {
+      try {
+        BufferedReader reader = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/componentHasStopped")));
+        String str = reader.readLine();
+        componentHasStopped = Integer.valueOf(str);
+        LOG.info("[msx-restart] componentHasStopped = " + componentHasStopped);
+        reader.close();
+      } catch(Exception e) {
+          e.printStackTrace();
+      }
+  }
+
+  private void recordComponentStopped() {
+      synchronized(hasStoppedLock) {
+          componentHasStopped = 1;
+      }
+  }
+
+  public void performReconfig(String component) throws Exception {
+    BufferedReader reader0 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/parameter")));
+    BufferedReader reader1 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/reconfig_mode")));
+    BufferedReader reader2 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/v1")));
+    BufferedReader reader3 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/v2")));
+    BufferedReader reader4 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/reconfig_component")));
+    String parameter, reconfigMode, v1, v2, reconfigComponent;
+    parameter = reconfigMode = v1 = v2 = reconfigComponent = "";
+    parameter = reader0.readLine();
+    reconfigMode = reader1.readLine();
+    v1 = reader2.readLine();
+    v2 = reader3.readLine();
+    reconfigComponent = reader4.readLine();
+    parameterReconfig = parameter; // global
+    reader0.close();
+    reader1.close();
+    reader2.close();
+    reader3.close();
+    reader4.close();
+    if (reconfigMode.equals("none")) {
+        LOG.info("[msx-restart] " + component + " init, reconfigMode is none, do nothing");
+    } else if (reconfigMode.equals("v1v1")) {
+        if (v1.equals(""))
+            System.exit(1);
+        this.getConf().set(parameter, v1);
+        LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v1=" + v1);
+    } else if (reconfigMode.equals("v2v2")) {
+        if (v2.equals(""))
+            System.exit(1);
+        this.getConf().set(parameter, v2);
+        LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v2=" + v2);
+    } else if (reconfigMode.equals("v1v2")) {
+        if (v1.equals("") || v2.equals(""))
+            System.exit(1);
+        synchronized(hasStoppedLock) {
+            synchronized(restartPerformedLock) {
+                if (reconfigComponent.equals(component) && restartPerformed == 0 && componentHasStopped == 1) {
+                    this.getConf().set(parameter, v2);
+                    LOG.info("[msx-restart] RECONFIG POINT!! " + component + " init, parameter=" + parameter
+                            + " reconfigMode=" + reconfigMode + " parameter=v2=" + v2);
+                    restartPerformed = 1;
+                } else {
+                    this.getConf().set(parameter, v1);
+                    LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v1=" + v1);
+                }
+            }
+        }
+    } else {
+        LOG.info("[msx-restart] ERROR!!!");
+    }
+  }
+
   /**
    * Creates a dummy DataNode for testing purpose.
    */
@@ -419,6 +499,12 @@
   @InterfaceAudience.LimitedPrivate("HDFS")
   DataNode(final Configuration conf) throws DiskErrorException {
     super(conf);
+    // msx
+    try {
+      performReconfig("DataNode");
+    } catch (Exception e) {
+      e.printStackTrace();
+    }
     this.tracer = createTracer(conf);
     this.tracerConfigurationManager =
         new TracerConfigurationManager(DATANODE_HTRACE_PREFIX, conf);
@@ -446,6 +532,12 @@
            final StorageLocationChecker storageLocationChecker,
            final SecureResources resources) throws IOException {
     super(conf);
+     // msx
+    try {
+      performReconfig("DataNode");
+    } catch (Exception e) {
+      e.printStackTrace();
+    }    
     this.tracer = createTracer(conf);
     this.tracerConfigurationManager =
         new TracerConfigurationManager(DATANODE_HTRACE_PREFIX, conf);
@@ -1976,6 +2068,10 @@
    * Otherwise, deadlock might occur.
    */
   public void shutdown() {
+    Configuration conf = this.getConf();
+    LOG.info("[msx-restart] DataNode stop, double check before stop, " + parameterReconfig + " = " + conf.get(parameterReconfig));
+    recordComponentStopped();
+    
     stopMetricsLogger();
     if (plugins != null) {
       for (ServicePlugin p : plugins) {
@@ -2633,6 +2729,7 @@
    *  If this thread is specifically interrupted, it will stop waiting.
    */
   public void runDatanodeDaemon() throws IOException {
+    LOG.info("[msx-restart] DataNode start");
     blockPoolManager.startAll();
 
     // start dataXceiveServer
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java	2020-01-01 13:19:04.662299072 -0600
@@ -166,6 +166,9 @@
 import static org.apache.hadoop.fs.CommonConfigurationKeys.IPC_NAMESPACE;
 import static org.apache.hadoop.fs.CommonConfigurationKeys.IPC_BACKOFF_ENABLE_DEFAULT;
 
+// msx
+import java.io.*;
+
 /**********************************************************
  * NameNode serves as both directory namespace manager and
  * "inode table" for the Hadoop DFS.  There is a single NameNode
@@ -910,9 +913,93 @@
     this(conf, NamenodeRole.NAMENODE);
   }
 
+  // msx
+  public static String parameterReconfig = ""; // just for value check during stop
+  public static int componentHasStopped = 0; // reset at the beginning of each Test
+  public static int restartPerformed = 0; // reset at the beginning of each Test
+  private static Object hasStoppedLock = new Object();
+  private static Object restartPerformedLock = new Object();
+  private static String controllerRootDir = "/root/parameter_test_controller/";
+  static {
+      try {
+        BufferedReader reader = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/componentHasStopped")));
+        String str = reader.readLine();
+        componentHasStopped = Integer.valueOf(str);
+        LOG.info("[msx-restart] componentHasStopped = " + componentHasStopped);
+        reader.close();
+      } catch(Exception e) {
+          e.printStackTrace();
+      }
+  }
+
+  private void recordComponentStopped() {
+      synchronized(hasStoppedLock) {
+          componentHasStopped = 1;
+      }
+  }
+  
+  public void performReconfig(String component) throws Exception {
+    BufferedReader reader0 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/parameter")));
+    BufferedReader reader1 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/reconfig_mode")));
+    BufferedReader reader2 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/v1")));
+    BufferedReader reader3 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/v2")));
+    BufferedReader reader4 = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/reconfig_component")));
+    String parameter, reconfigMode, v1, v2, reconfigComponent;
+    parameter = reconfigMode = v1 = v2 = reconfigComponent = "";
+    parameter = reader0.readLine();
+    reconfigMode = reader1.readLine();
+    v1 = reader2.readLine();
+    v2 = reader3.readLine();
+    reconfigComponent = reader4.readLine();
+    parameterReconfig = parameter; // global
+    reader0.close();
+    reader1.close();
+    reader2.close();
+    reader3.close();
+    reader4.close();
+    if (reconfigMode.equals("none")) {
+        LOG.info("[msx-restart] " + component + " init, reconfigMode is none, do nothing");
+    } else if (reconfigMode.equals("v1v1")) {
+        if (v1.equals(""))
+            System.exit(1);
+        this.getConf().set(parameter, v1);
+        LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v1=" + v1);
+    } else if (reconfigMode.equals("v2v2")) {
+        if (v2.equals(""))
+            System.exit(1);
+        this.getConf().set(parameter, v2);
+        LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v2=" + v2);
+    } else if (reconfigMode.equals("v1v2")) {
+        if (v1.equals("") || v2.equals(""))
+            System.exit(1);
+        synchronized(hasStoppedLock) {
+            synchronized(restartPerformedLock) {
+                if (reconfigComponent.equals(component) && restartPerformed == 0 && componentHasStopped == 1) {
+                    this.getConf().set(parameter, v2);
+                    LOG.info("[msx-restart] RECONFIG POINT!! " + component + " init, parameter=" + parameter
+                            + " reconfigMode=" + reconfigMode + " parameter=v2=" + v2);
+                    restartPerformed = 1;
+                } else {
+                    this.getConf().set(parameter, v1);
+                    LOG.info("[msx-restart] " + component + " init, parameter=" + parameter + " reconfigMode=" + reconfigMode + " parameter=v1=" + v1);
+                }
+            }
+        }
+    } else {
+        LOG.info("[msx-restart] ERROR!!!");
+    }
+  } 
+ 
   protected NameNode(Configuration conf, NamenodeRole role)
       throws IOException {
     super(conf);
+
+    // msx
+    try {
+      performReconfig("NameNode");
+    } catch (Exception e) {
+        e.printStackTrace();
+    }
     this.tracer = new Tracer.Builder("NameNode").
         conf(TraceUtils.wrapHadoopConf(NAMENODE_HTRACE_PREFIX, conf)).
         build();
@@ -949,6 +1036,7 @@
       this.stopAtException(e);
       throw e;
     }
+    LOG.info("[msx-restart] NameNode start");
     this.started.set(true);
   }
 
@@ -990,6 +1078,10 @@
    * Stop all NameNode threads and wait for all to finish.
    */
   public void stop() {
+    Configuration conf = this.getConf();
+    LOG.info("[msx-restart] NameNode stop, double check before stop, " + parameterReconfig + " = " + conf.get(parameterReconfig));
+    recordComponentStopped();
+
     synchronized(this) {
       if (stopRequested)
         return;
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/MyRunListener.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/MyRunListener.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/MyRunListener.java	1969-12-31 18:00:00.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/MyRunListener.java	2020-01-01 13:49:38.535248145 -0600
@@ -0,0 +1,108 @@
+import org.junit.runner.notification.*;
+import org.junit.runner.Description;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+import org.junit.runner.notification.RunListener;
+
+import java.io.BufferedWriter;
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.FileWriter;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.io.PrintWriter;
+
+import org.apache.commons.lang.exception.ExceptionUtils;
+import org.apache.hadoop.hdfs.qjournal.server.JournalNode;
+import org.apache.hadoop.hdfs.server.namenode.NameNode;
+import org.apache.hadoop.hdfs.server.datanode.DataNode;
+
+public class MyRunListener extends RunListener {
+
+    public String controllerRootDir = "/root/parameter_test_controller/";
+    public String resultDirName = controllerRootDir + "shared/test_results/";
+    public String result = "";
+    public String SEPERATOR = "@@@";
+    public String failureMessage = "";
+    public String stackTrace = "";
+    public String testName = "";
+    public MyRunListener() {
+        System.out.println("[msx] Creation of Run Listener...");
+    }
+
+    public void reset() {
+        try {
+            BufferedReader reader = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/componentHasStopped")));
+            String str = reader.readLine();
+            int componentHasStoppedDefault = Integer.valueOf(str);
+	    int restartPerformedDefault = 0;
+            reader.close();
+	    NameNode.componentHasStopped = componentHasStoppedDefault;
+	    DataNode.componentHasStopped = componentHasStoppedDefault;
+	    JournalNode.componentHasStopped = componentHasStoppedDefault;
+
+	    NameNode.restartPerformed = restartPerformedDefault;
+	    DataNode.restartPerformed = restartPerformedDefault;
+	    JournalNode.restartPerformed = restartPerformedDefault;
+            
+	    System.out.println("[msx] componentHasStopped has been reset to " + componentHasStoppedDefault);
+	    System.out.println("[msx] restartPerformedDefault has been reset to " + restartPerformedDefault);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }        
+    }
+ 
+    public void testStarted(Description description) throws java.lang.Exception {
+	result = "1"; // clean up
+        failureMessage = "none";
+        stackTrace = "none";
+        testName = description.getClassName() + "#" + description.getMethodName();
+        System.out.println("[msx] test Started " + testName);
+    }
+ 
+    public void testFinished(Description description) throws java.lang.Exception {
+        System.out.println("[msx] test Finished " + testName + " test result = " + result);
+        BufferedWriter writer = new BufferedWriter(new FileWriter(resultDirName + testName)); 
+        writer.write(testName + SEPERATOR + result + SEPERATOR + failureMessage + SEPERATOR + stackTrace + SEPERATOR);
+        writer.flush();
+        writer.close();
+        reset();
+    }
+ 
+    public void testFailure(Failure failure) throws java.lang.Exception {
+        result = "-1";
+        failureMessage = failure.getMessage();
+        stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+        System.out.println("[msx] testFailure " + testName + " test result = " + result);
+    }
+ 
+    public void testIgnored(Description description) throws java.lang.Exception {
+        result = "0";
+        System.out.println("[msx] test Ignored " + testName);
+    }
+     
+    public void testAssumptionFailure(Failure failure) {
+        try {
+            result = "-2";
+            String failureMessage = failure.getMessage();
+            String stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+            System.out.println("[msx] testAssumptionFailure " + testName + " test result = " + result);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }
+    }
+    
+    // Called before any tests have been run.
+    public void testRunStarted(Description description) throws java.lang.Exception {
+        System.out.println("[msx] testRunStarted " + description.testCount());
+    }
+ 
+    // Called when all tests have finished
+    public void testRunFinished(Result result) throws java.lang.Exception {
+        System.out.println("[msx] testRunFinished " + result.getRunCount());
+    }
+}
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractAppend.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractAppend.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractAppend.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractAppend.java	2020-01-01 13:19:04.682299388 -0600
@@ -26,6 +26,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractConcat.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractConcat.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractConcat.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractConcat.java	2020-01-01 13:19:04.682299388 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
     // perform a simple operation on the cluster to verify it is up
     HDFSContract.getCluster().getFileSystem().getDefaultBlockSize();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractCreate.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractCreate.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractCreate.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractCreate.java	2020-01-01 13:19:04.682299388 -0600
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractDelete.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractDelete.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractDelete.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractDelete.java	2020-01-01 13:19:04.682299388 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractGetFileStatus.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractGetFileStatus.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractGetFileStatus.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractGetFileStatus.java	2020-01-01 13:19:04.682299388 -0600
@@ -31,6 +31,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractMkdir.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractMkdir.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractMkdir.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractMkdir.java	2020-01-01 13:19:04.682299388 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractOpen.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractOpen.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractOpen.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractOpen.java	2020-01-01 13:19:04.682299388 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java	2020-01-01 13:19:04.682299388 -0600
@@ -40,6 +40,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRename.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRename.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRename.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRename.java	2020-01-01 13:19:04.682299388 -0600
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRootDirectory.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRootDirectory.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRootDirectory.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRootDirectory.java	2020-01-01 13:19:04.682299388 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSeek.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSeek.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSeek.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSeek.java	2020-01-01 13:19:04.682299388 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSetTimes.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSetTimes.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSetTimes.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSetTimes.java	2020-01-01 13:19:04.682299388 -0600
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java	2020-01-01 13:19:04.682299388 -0600
@@ -68,6 +68,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java	2020-01-01 13:19:04.682299388 -0600
@@ -87,6 +87,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     sockDir = new TemporarySocketDirectory();
     DomainSocket.disableBindPathValidation();
     prevCacheManipulator = NativeIO.POSIX.getCacheManipulator();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java	2020-01-01 13:19:04.682299388 -0600
@@ -47,6 +47,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining()
                                     throws IOException, LoginException, URISyntaxException  {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
     fc = FileContext.getFileContext(cluster.getURI(0), conf);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java	2020-01-01 13:19:04.682299388 -0600
@@ -54,6 +54,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining()
                                     throws IOException, LoginException, URISyntaxException  {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
     fc = FileContext.getFileContext(cluster.getURI(0), conf);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java	2020-01-01 13:19:04.682299388 -0600
@@ -84,6 +84,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining()
         throws IOException, LoginException, URISyntaxException  {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     // set permissions very restrictive
     conf.set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY,  "077");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java	2020-01-01 13:19:04.682299388 -0600
@@ -67,6 +67,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     final Configuration conf = new HdfsConfiguration();
     dfsCluster = new MiniDFSCluster.Builder(conf).build();
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java	2020-01-01 13:19:04.682299388 -0600
@@ -57,6 +57,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(2).build();
     cluster.waitClusterUp();
     URI uri0 = cluster.getURI(0);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java	2020-01-01 13:19:04.682299388 -0600
@@ -55,6 +55,7 @@
 
   @BeforeClass
   public static void setUp() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     conf.setBoolean(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY, true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSWebHdfsFileContextMainOperations.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSWebHdfsFileContextMainOperations.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSWebHdfsFileContextMainOperations.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSWebHdfsFileContextMainOperations.java	2020-01-01 13:19:04.682299388 -0600
@@ -60,6 +60,7 @@
   @BeforeClass
   public static void clusterSetupAtBeginning()
       throws IOException, LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
 
     File base = new File(BASEDIR);
     FileUtil.fullyDelete(base);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileContext.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileContext.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileContext.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileContext.java	2020-01-01 13:19:04.682299388 -0600
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void testSetup() throws Exception {
+System.out.println("[msx] before_class");
     fc = FileContext.getFileContext(cluster.getURI(0));
     wrapper = new FileContextTestWrapper(fc, "/tmp/TestSymlinkHdfsFileContext");
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java	2020-01-01 13:19:04.682299388 -0600
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void testSetup() throws Exception {
+System.out.println("[msx] before_class");
     wrapper = new FileSystemTestWrapper(dfs, "/tmp/TestSymlinkHdfsFileSystem");
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java	2020-01-01 13:19:04.682299388 -0600
@@ -86,6 +86,7 @@
 
   @BeforeClass
   public static void beforeClassSetup() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     conf.set(FsPermission.UMASK_LABEL, "000");
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_MAX_COMPONENT_LENGTH_KEY, 0);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUrlStreamHandler.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUrlStreamHandler.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUrlStreamHandler.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUrlStreamHandler.java	2020-01-01 13:19:04.682299388 -0600
@@ -50,6 +50,7 @@
 
   @BeforeClass
   public static void setupHandler() {
+System.out.println("[msx] before_class");
 
     // Setup our own factory
     // setURLStreamHandlerFactor is can be set at most once in the JVM
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestWebHdfsFileContextMainOperations.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestWebHdfsFileContextMainOperations.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestWebHdfsFileContextMainOperations.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestWebHdfsFileContextMainOperations.java	2020-01-01 13:19:04.682299388 -0600
@@ -74,6 +74,7 @@
   @BeforeClass
   public static void clusterSetupAtBeginning()
       throws IOException, LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
 
     cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(2).build();
     cluster.waitClusterUp();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java	2020-01-01 13:19:04.682299388 -0600
@@ -51,6 +51,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY, true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java	2020-01-01 13:19:04.682299388 -0600
@@ -83,6 +83,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
 
     // Encryption Zone settings
     FileSystemTestHelper fsHelper = new FileSystemTestHelper();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java	2020-01-01 13:19:04.682299388 -0600
@@ -76,6 +76,7 @@
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY,
         true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkMergeSlash.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkMergeSlash.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkMergeSlash.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkMergeSlash.java	2020-01-01 13:19:04.682299388 -0600
@@ -77,6 +77,7 @@
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY,
         true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java	2020-01-01 13:19:04.682299388 -0600
@@ -63,6 +63,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     clusterConf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithTruncate.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithTruncate.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithTruncate.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithTruncate.java	2020-01-01 13:19:04.682299388 -0600
@@ -55,6 +55,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
         .numDataNodes(2).build();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithXAttrs.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithXAttrs.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithXAttrs.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithXAttrs.java	2020-01-01 13:19:04.682299388 -0600
@@ -59,6 +59,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
         .numDataNodes(2)
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java	2020-01-01 13:19:04.682299388 -0600
@@ -52,6 +52,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY, true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java	2020-01-01 13:19:04.682299388 -0600
@@ -77,6 +77,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
 
     CONF.setLong(DFS_BLOCK_SIZE_KEY, DFS_BLOCK_SIZE_DEFAULT);
     CONF.setInt(DFS_BYTES_PER_CHECKSUM_KEY, DFS_BYTES_PER_CHECKSUM_DEFAULT);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java	2020-01-01 13:19:04.682299388 -0600
@@ -62,6 +62,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(2).build();
     cluster.waitClusterUp();
     fHdfs = cluster.getFileSystem();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java	2020-01-01 13:19:04.682299388 -0600
@@ -49,6 +49,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY, true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java	2020-01-01 13:19:04.682299388 -0600
@@ -63,6 +63,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     clusterConf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithXAttrs.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithXAttrs.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithXAttrs.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithXAttrs.java	2020-01-01 13:19:04.682299388 -0600
@@ -58,6 +58,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
         .numDataNodes(2)
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java	2020-01-01 13:19:04.682299388 -0600
@@ -63,6 +63,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     sockDir = new TemporarySocketDirectory();
     DomainSocket.disableBindPathValidation();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocalLegacy.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocalLegacy.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocalLegacy.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocalLegacy.java	2020-01-01 13:19:04.682299388 -0600
@@ -57,6 +57,7 @@
 public class TestBlockReaderLocalLegacy {
   @BeforeClass
   public static void setupCluster() throws IOException {
+System.out.println("[msx] before_class");
     DFSInputStream.tcpReadsDisabledForTesting = true;
     DomainSocket.disableBindPathValidation();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java	2020-01-01 13:19:04.682299388 -0600
@@ -46,6 +46,7 @@
   }
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     final int REPLICATION_FACTOR = 1;
     util = new BlockReaderTestUtil(REPLICATION_FACTOR);
     util.writeFile(TEST_FILE, FILE_SIZE_K);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/crypto/TestHdfsCryptoStreams.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/crypto/TestHdfsCryptoStreams.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/crypto/TestHdfsCryptoStreams.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/crypto/TestHdfsCryptoStreams.java	2020-01-01 13:19:04.682299388 -0600
@@ -45,6 +45,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     dfsCluster = new MiniDFSCluster.Builder(conf).build();
     dfsCluster.waitClusterUp();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/FileAppendTest4.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/FileAppendTest4.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/FileAppendTest4.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/FileAppendTest4.java	2020-01-01 13:19:04.706299767 -0600
@@ -60,6 +60,7 @@
   
   @BeforeClass
   public static void startUp () throws IOException {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     init(conf);
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java	2020-01-01 13:19:04.682299388 -0600
@@ -85,6 +85,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     racks = new String[NODE_NUM];
     hosts = new String[NODE_NUM];
     types = new StorageType[NODE_NUM];
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferTestCase.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferTestCase.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferTestCase.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferTestCase.java	2020-01-01 13:19:04.682299388 -0600
@@ -77,6 +77,7 @@
 
   @BeforeClass
   public static void initKdc() throws Exception {
+System.out.println("[msx] before_class");
     baseDir = GenericTestUtils
         .getTestDir(SaslDataTransferTestCase.class.getSimpleName());
     FileUtil.fullyDelete(baseDir);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java	2020-01-01 13:19:04.686299451 -0600
@@ -87,6 +87,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     baseDir =
         GenericTestUtils.getTestDir(TestSecureNNWithQJM.class.getSimpleName());
     FileUtil.fullyDelete(baseDir);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java	2020-01-01 13:19:04.686299451 -0600
@@ -97,6 +97,7 @@
   
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     config = new HdfsConfiguration();
     config.setLong(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_MAX_LIFETIME_KEY, 10000);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestAvailableSpaceBlockPlacementPolicy.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestAvailableSpaceBlockPlacementPolicy.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestAvailableSpaceBlockPlacementPolicy.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestAvailableSpaceBlockPlacementPolicy.java	2020-01-01 13:19:04.686299451 -0600
@@ -56,6 +56,7 @@
 
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setFloat(
       DFSConfigKeys.DFS_NAMENODE_AVAILABLE_SPACE_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_PREFERENCE_FRACTION_KEY,
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java	2020-01-01 13:19:04.686299451 -0600
@@ -59,6 +59,7 @@
 
   @BeforeClass
   public static void raiseBlockManagerLogLevels() {
+System.out.println("[msx] before_class");
     GenericTestUtils.setLogLevel(BlockManager.LOG, Level.ALL);
     GenericTestUtils.setLogLevel(BlockReportLeaseManager.LOG, Level.ALL);
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java	2020-01-01 13:19:04.686299451 -0600
@@ -96,6 +96,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_INTERVAL_SECONDS_KEY, 1);
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_CONSIDERLOAD_KEY,
         false);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedStripedBlock.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedStripedBlock.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedStripedBlock.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedStripedBlock.java	2020-01-01 13:19:04.686299451 -0600
@@ -65,6 +65,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     dm = mockDatanodeManager();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java	2020-01-01 13:19:04.686299451 -0600
@@ -57,6 +57,7 @@
   // allow user with TGT to run tests
   @BeforeClass
   public static void setupKerb() {
+System.out.println("[msx] before_class");
     System.setProperty("java.security.krb5.kdc", "");
     System.setProperty("java.security.krb5.realm", "NONE");
   }    
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java	2020-01-01 13:19:04.690299514 -0600
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     DomainSocket.disableBindPathValidation();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java	2020-01-01 13:19:04.690299514 -0600
@@ -58,6 +58,7 @@
 
   @BeforeClass
   public static void setupTest() {
+System.out.println("[msx] before_class");
     EditLogFileOutputStream.setShouldSkipFsyncForTesting(true);
 
     // Track calls to posix_fadvise.
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java	2020-01-01 13:19:04.686299451 -0600
@@ -61,6 +61,7 @@
 
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
+System.out.println("[msx] before_class");
     baseConf = new HdfsConfiguration();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java	2020-01-01 13:19:04.690299514 -0600
@@ -131,6 +131,7 @@
 
   @BeforeClass
   public static void setUpClass() throws Exception {
+System.out.println("[msx] before_class");
     oldInjector = DataNodeFaultInjector.get();
     DataNodeFaultInjector.set(new DataNodeFaultInjector() {
       @Override
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java	2020-01-01 13:19:04.690299514 -0600
@@ -61,6 +61,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     DFSTestUtil.setNameNodeLogLevel(Level.WARN);
     FsDatasetImplTestUtils.setFsDatasetImplLogLevel(Level.WARN);
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java	2020-01-01 13:19:04.698299641 -0600
@@ -100,6 +100,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java	2020-01-01 13:19:04.694299578 -0600
@@ -79,6 +79,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     initCluster(true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDisallowModifyROSnapshot.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDisallowModifyROSnapshot.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDisallowModifyROSnapshot.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDisallowModifyROSnapshot.java	2020-01-01 13:19:04.694299578 -0600
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
     cluster.waitActive();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java	2020-01-01 13:19:04.694299578 -0600
@@ -72,6 +72,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);
     initCluster(true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java	2020-01-01 13:19:04.694299578 -0600
@@ -61,6 +61,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     config = new Configuration();
     if ( DFS_BASE_DIR.exists() && !FileUtil.fullyDelete(DFS_BASE_DIR) ) {
       throw new IOException("Could not delete hdfs directory '" + DFS_BASE_DIR +
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java	2020-01-01 13:19:04.694299578 -0600
@@ -58,6 +58,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
     cluster.waitActive();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDiskspaceQuotaUpdate.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDiskspaceQuotaUpdate.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDiskspaceQuotaUpdate.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDiskspaceQuotaUpdate.java	2020-01-01 13:19:04.698299641 -0600
@@ -70,6 +70,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, BLOCKSIZE);
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION)
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java	2020-01-01 13:19:04.698299641 -0600
@@ -47,6 +47,7 @@
 
   @BeforeClass
   public static void disableFsync() {
+System.out.println("[msx] before_class");
     // No need to fsync for the purposes of tests. This makes
     // the tests run much faster.
     EditLogFileOutputStream.setShouldSkipFsyncForTesting(true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java	2020-01-01 13:19:04.698299641 -0600
@@ -66,6 +66,7 @@
   
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES)
         .build();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java	2020-01-01 13:19:04.694299578 -0600
@@ -37,6 +37,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     startCluster();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java	2020-01-01 13:19:04.694299578 -0600
@@ -47,6 +47,7 @@
 
   @BeforeClass
   public static void setUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithXAttr.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithXAttr.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithXAttr.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithXAttr.java	2020-01-01 13:19:04.698299641 -0600
@@ -54,6 +54,7 @@
 
   @BeforeClass
   public static void setUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeAcl.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeAcl.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeAcl.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeAcl.java	2020-01-01 13:19:04.698299641 -0600
@@ -28,6 +28,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     startCluster();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeHttpServer.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeHttpServer.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeHttpServer.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeHttpServer.java	2020-01-01 13:19:04.698299641 -0600
@@ -66,6 +66,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     File base = new File(BASEDIR);
     FileUtil.fullyDelete(base);
     base.mkdirs();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java	2020-01-01 13:19:04.698299641 -0600
@@ -35,6 +35,7 @@
 
   @BeforeClass
   public static void setUp() {
+System.out.println("[msx] before_class");
     ExitUtil.disableSystemExit();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSecondaryWebUi.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSecondaryWebUi.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSecondaryWebUi.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSecondaryWebUi.java	2020-01-01 13:19:04.690299514 -0600
@@ -41,6 +41,7 @@
   
   @BeforeClass
   public static void setUpCluster() throws IOException {
+System.out.println("[msx] before_class");
     conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,
         "0.0.0.0:0");
     conf.setLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, 500);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSnapshotPathINodes.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSnapshotPathINodes.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSnapshotPathINodes.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSnapshotPathINodes.java	2020-01-01 13:19:04.698299641 -0600
@@ -59,6 +59,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = new Configuration();
     cluster = new MiniDFSCluster.Builder(conf)
       .numDataNodes(REPLICATION)
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java	2020-01-01 13:19:04.698299641 -0600
@@ -80,6 +80,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     sockDir = new TemporarySocketDirectory();
     DomainSocket.disableBindPathValidation();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java	2020-01-01 13:19:04.706299767 -0600
@@ -91,6 +91,7 @@
 
   @BeforeClass
   public static void captureUser() throws IOException {
+System.out.println("[msx] before_class");
     realUgi = UserGroupInformation.getCurrentUser();
     realUser = System.getProperty("user.name");
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java	2020-01-01 13:19:04.706299767 -0600
@@ -46,6 +46,7 @@
 
   @BeforeClass
   public static void setupCluster() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, 4096);
     conf.set("fs.hdfs.impl.disable.cache", "true");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java	2020-01-01 13:19:04.706299767 -0600
@@ -79,6 +79,7 @@
 
   @BeforeClass
   public static void startUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setLong(DFSConfigKeys.DFS_NAMENODE_MIN_BLOCK_SIZE_KEY, BLOCK_SIZE);
     conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY, BLOCK_SIZE);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeConfig.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeConfig.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeConfig.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeConfig.java	2020-01-01 13:19:04.686299451 -0600
@@ -49,6 +49,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     clearBaseDir();
     Configuration conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_DATANODE_HTTPS_PORT_KEY, 0);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataStream.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataStream.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataStream.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataStream.java	2020-01-01 13:19:04.702299704 -0600
@@ -37,6 +37,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new Configuration();
     conf.setInt(HdfsClientConfigKeys.DFS_CLIENT_WRITE_PACKET_SIZE_KEY,
         PACKET_SIZE);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java	2020-01-01 13:19:04.706299767 -0600
@@ -84,6 +84,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new Configuration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java	2020-01-01 13:19:04.706299767 -0600
@@ -107,6 +107,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     final Configuration conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
     conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, BLOCK_SIZE);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java	2020-01-01 13:19:04.698299641 -0600
@@ -213,6 +213,7 @@
   
   @BeforeClass
   public static void initialize() throws Exception {
+System.out.println("[msx] before_class");
     UpgradeUtilities.initialize();
   }
   
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodeBenchmarkThroughput.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodeBenchmarkThroughput.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodeBenchmarkThroughput.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodeBenchmarkThroughput.java	2020-01-01 13:19:04.682299388 -0600
@@ -45,6 +45,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     int numDN = ErasureCodeBenchmarkThroughput.getEcPolicy().getNumDataUnits() +
         ErasureCodeBenchmarkThroughput.getEcPolicy().getNumParityUnits();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java	2020-01-01 13:19:04.706299767 -0600
@@ -67,6 +67,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(conf)
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFetchImage.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFetchImage.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFetchImage.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFetchImage.java	2020-01-01 13:19:04.706299767 -0600
@@ -60,6 +60,7 @@
 
   @BeforeClass
   public static void setupImageDir() {
+System.out.println("[msx] before_class");
     FETCHED_IMAGE_FILE.mkdirs();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java	2020-01-01 13:19:04.706299767 -0600
@@ -73,6 +73,7 @@
 
   @BeforeClass
   public static void setUp() throws java.lang.Exception {
+System.out.println("[msx] before_class");
     AppendTestUtil.LOG.info("setUp()");
     conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY, 512);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java	2020-01-01 13:19:04.706299767 -0600
@@ -65,6 +65,7 @@
   
   @BeforeClass
   public static void testSetUp() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_LIST_LIMIT, 2);
     cluster = new MiniDFSCluster.Builder(conf).build();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSPolicyProvider.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSPolicyProvider.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSPolicyProvider.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSPolicyProvider.java	2020-01-01 13:19:04.706299767 -0600
@@ -76,6 +76,7 @@
 
   @BeforeClass
   public static void initialize() {
+System.out.println("[msx] before_class");
     Service[] services = new HDFSPolicyProvider().getServices();
     policyProviderProtocols = new HashSet<>(services.length);
     for (Service service : services) {
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java	2020-01-01 13:19:04.702299704 -0600
@@ -67,6 +67,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
     fs = FileSystem.get(conf);
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestIsMethodSupported.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestIsMethodSupported.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestIsMethodSupported.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestIsMethodSupported.java	2020-01-01 13:19:04.702299704 -0600
@@ -61,6 +61,7 @@
   
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = (new MiniDFSCluster.Builder(conf))
         .numDataNodes(1).build();
     nnAddress = cluster.getNameNode().getNameNodeAddress();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java	2020-01-01 13:19:04.702299704 -0600
@@ -38,6 +38,7 @@
 
   @BeforeClass
   public static void testSetUp() throws Exception {
+System.out.println("[msx] before_class");
     setTestPaths(new Path("/tmp/TestListFilesInDFS"));
     cluster = new MiniDFSCluster.Builder(conf).build();
     fs = cluster.getFileSystem();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java	2020-01-01 13:19:04.702299704 -0600
@@ -64,6 +64,7 @@
 
   @BeforeClass
   public static void testSetUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(conf).build();
     fc = FileContext.getFileContext(cluster.getConfiguration(0));
     fc.delete(TEST_DIR, true);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java	2020-01-01 13:19:04.706299767 -0600
@@ -24,6 +24,7 @@
 public class TestParallelRead extends TestParallelReadUtil {
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     // This is a test of the normal (TCP) read path.  For this reason, we turn
     // off both short-circuit local reads and UNIX domain socket data traffic.
     HdfsConfiguration conf = new HdfsConfiguration();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitLegacyRead.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitLegacyRead.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitLegacyRead.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitLegacyRead.java	2020-01-01 13:19:04.706299767 -0600
@@ -26,6 +26,7 @@
 public class TestParallelShortCircuitLegacyRead extends TestParallelReadUtil {
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     DFSInputStream.tcpReadsDisabledForTesting = true;
     HdfsConfiguration conf = new HdfsConfiguration();
     conf.set(DFSConfigKeys.DFS_DOMAIN_SOCKET_PATH_KEY, "");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitRead.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitRead.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitRead.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitRead.java	2020-01-01 13:19:04.682299388 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     if (DomainSocket.getLoadingFailureReason() != null) return;
     DFSInputStream.tcpReadsDisabledForTesting = true;
     sockDir = new TemporarySocketDirectory();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadNoChecksum.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadNoChecksum.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadNoChecksum.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadNoChecksum.java	2020-01-01 13:19:04.706299767 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     if (DomainSocket.getLoadingFailureReason() != null) return;
     DFSInputStream.tcpReadsDisabledForTesting = true;
     sockDir = new TemporarySocketDirectory();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadUnCached.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadUnCached.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadUnCached.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadUnCached.java	2020-01-01 13:19:04.706299767 -0600
@@ -38,6 +38,7 @@
 
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     if (DomainSocket.getLoadingFailureReason() != null) return;
     sockDir = new TemporarySocketDirectory();
     HdfsConfiguration conf = new HdfsConfiguration();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelUnixDomainRead.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelUnixDomainRead.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelUnixDomainRead.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelUnixDomainRead.java	2020-01-01 13:19:04.686299451 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     if (DomainSocket.getLoadingFailureReason() != null) return;
     DFSInputStream.tcpReadsDisabledForTesting = true;
     sockDir = new TemporarySocketDirectory();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java	2020-01-01 13:19:04.706299767 -0600
@@ -92,6 +92,7 @@
 
   @BeforeClass
   public static void setUpClass() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.set(
         MiniDFSCluster.HDFS_MINIDFS_BASEDIR,
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingCorruptData.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingCorruptData.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingCorruptData.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingCorruptData.java	2020-01-01 13:19:04.706299767 -0600
@@ -49,6 +49,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     cluster = initializeCluster();
     dfs = cluster.getFileSystem();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingDeletedData.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingDeletedData.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingDeletedData.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingDeletedData.java	2020-01-01 13:19:04.702299704 -0600
@@ -50,6 +50,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     cluster = initializeCluster();
     dfs = cluster.getFileSystem();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDNFailure.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDNFailure.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDNFailure.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDNFailure.java	2020-01-01 13:19:04.702299704 -0600
@@ -54,6 +54,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     cluster = initializeCluster();
     dfs = cluster.getFileSystem();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java	2020-01-01 13:19:04.698299641 -0600
@@ -134,6 +134,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     baseDir = getTestDir();
     FileUtil.fullyDelete(baseDir);
     assertTrue(baseDir.mkdirs());
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java	2020-01-01 13:19:04.682299388 -0600
@@ -44,6 +44,7 @@
   
   @BeforeClass
   public static void clusterSetUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_SNAPSHOT_MAX_LIMIT, 3);
     cluster = new MiniDFSCluster.Builder(conf).build();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java	2020-01-01 13:19:04.706299767 -0600
@@ -120,6 +120,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     baseDir = getTestDir();
     FileUtil.fullyDelete(baseDir);
     assertTrue(baseDir.mkdirs());
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForAcl.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForAcl.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForAcl.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForAcl.java	2020-01-01 13:19:04.702299704 -0600
@@ -95,6 +95,7 @@
    */
   @BeforeClass
   public static void createOriginalFSImage() throws IOException {
+System.out.println("[msx] before_class");
     MiniDFSCluster cluster = null;
     try {
       Configuration conf = new Configuration();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java	2020-01-01 13:19:04.698299641 -0600
@@ -61,6 +61,7 @@
    */
   @BeforeClass
   public static void createOriginalFSImage() throws IOException {
+System.out.println("[msx] before_class");
     MiniDFSCluster cluster = null;
     Configuration conf = new Configuration();
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java	2020-01-01 13:19:04.698299641 -0600
@@ -67,6 +67,7 @@
    */
   @BeforeClass
   public static void createOriginalFSImage() throws IOException {
+System.out.println("[msx] before_class");
     MiniDFSCluster cluster = null;
     Configuration conf = new Configuration();
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java	2020-01-01 13:19:04.698299641 -0600
@@ -143,6 +143,7 @@
   // multiple tests.
   @BeforeClass
   public static void createOriginalFSImage() throws IOException {
+System.out.println("[msx] before_class");
     File[] nnDirs = MiniDFSCluster.getNameNodeDirectory(
         MiniDFSCluster.getBaseDirectory(), 0, 0);
     tempDir = nnDirs[0];
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/FoldedTreeSetTest.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/FoldedTreeSetTest.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/FoldedTreeSetTest.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/FoldedTreeSetTest.java	2020-01-01 13:19:04.702299704 -0600
@@ -43,6 +43,7 @@
 
   @BeforeClass
   public static void setUpClass() {
+System.out.println("[msx] before_class");
     long seed = System.nanoTime();
     System.out.println("This run uses the random seed " + seed);
     srand = new Random(seed);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java	2020-01-01 13:19:04.702299704 -0600
@@ -70,6 +70,7 @@
 
   @BeforeClass
   public static void setupCluster() {
+System.out.println("[msx] before_class");
     final Configuration conf = new Configuration();
     conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, 1024);
     try {
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java	2020-01-01 13:19:04.702299704 -0600
@@ -51,6 +51,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.set(DFSConfigKeys.DFS_HTTP_POLICY_KEY, HttpConfig.Policy.HTTPS_ONLY.name());
     conf.set(DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_KEY, "localhost:0");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSAcl.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSAcl.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSAcl.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSAcl.java	2020-01-01 13:19:04.702299704 -0600
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = WebHdfsTestUtil.createConf();
     startCluster();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java	2020-01-01 13:19:04.702299704 -0600
@@ -68,6 +68,7 @@
 
   @BeforeClass
   public static void setUp() {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     SecurityUtil.setAuthenticationMethod(KERBEROS, conf);
     UserGroupInformation.setConfiguration(conf);    
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithAuthenticationFilter.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithAuthenticationFilter.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithAuthenticationFilter.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithAuthenticationFilter.java	2020-01-01 13:19:04.702299704 -0600
@@ -71,6 +71,7 @@
 
   @BeforeClass
   public static void setUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.set(DFSConfigKeys.DFS_WEBHDFS_AUTHENTICATION_FILTER_KEY,
         CustomizedFilter.class.getName());
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java	2020-01-01 13:19:04.702299704 -0600
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void setupTest() {
+System.out.println("[msx] before_class");
     setLogLevel();
     try {
       setupCluster(4, 3);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/metrics2/sink/TestRollingFileSystemSinkWithSecureHdfs.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/metrics2/sink/TestRollingFileSystemSinkWithSecureHdfs.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/metrics2/sink/TestRollingFileSystemSinkWithSecureHdfs.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/metrics2/sink/TestRollingFileSystemSinkWithSecureHdfs.java	2020-01-01 13:19:04.710299830 -0600
@@ -79,6 +79,7 @@
    */
   @BeforeClass
   public static void initKdc() throws Exception {
+System.out.println("[msx] before_class");
     Properties kdcConf = MiniKdc.createConf();
     kdc = new MiniKdc(kdcConf, ROOT_TEST_DIR);
     kdc.start();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/security/TestPermissionSymlinks.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/security/TestPermissionSymlinks.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/security/TestPermissionSymlinks.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/security/TestPermissionSymlinks.java	2020-01-01 13:19:04.710299830 -0600
@@ -71,6 +71,7 @@
   
   @BeforeClass
   public static void beforeClassSetUp() throws Exception {
+System.out.println("[msx] before_class");
     conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     conf.set(FsPermission.UMASK_LABEL, "000");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java	2020-01-01 13:19:04.710299830 -0600
@@ -53,6 +53,7 @@
 
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
+System.out.println("[msx] before_class");
     config = new Configuration();
     config.set("hadoop.security.authorization", "true");
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tools/TestTools.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tools/TestTools.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tools/TestTools.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tools/TestTools.java	2020-01-01 13:19:04.710299830 -0600
@@ -43,6 +43,7 @@
 
   @BeforeClass
   public static void before() {
+System.out.println("[msx] before_class");
     ExitUtil.disableSystemExit();
     OPTIONS[1] = INVALID_OPTION;
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java
--- ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java	2020-01-01 13:19:04.710299830 -0600
@@ -52,6 +52,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     sockDir = new TemporarySocketDirectory();
     DomainSocket.disableBindPathValidation();
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-client/pom.xml /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/pom.xml
--- ./hadoop-hdfs-project/hadoop-hdfs-client/pom.xml	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/pom.xml	2020-01-01 13:48:01.957723595 -0600
@@ -34,6 +34,12 @@
   </properties>
 
   <dependencies>
+    <!--<dependency>
+      <groupId>org.apache.hadoop</groupId>
+      <artifactId>hadoop-hdfs</artifactId>
+      <scope>provided</scope>
+      <systemPath>/root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-3.1.2.jar</systemPath>
+    </dependency>-->
     <dependency>
       <groupId>com.squareup.okhttp</groupId>
       <artifactId>okhttp</artifactId>
@@ -120,6 +126,15 @@
       <plugin>
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-surefire-plugin</artifactId>
+    <version>3.0.0-M4</version>
+    <configuration>
+      <properties>
+        <property>
+          <name>listener</name>
+          <value>MyRunListener</value>
+        </property>
+      </properties>
+    </configuration>
       </plugin>
       <plugin>
         <groupId>org.apache.rat</groupId>
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/MyRunListener.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/MyRunListener.java
--- ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/MyRunListener.java	1969-12-31 18:00:00.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/MyRunListener.java	2020-01-01 13:48:42.986371264 -0600
@@ -0,0 +1,108 @@
+import org.junit.runner.notification.*;
+import org.junit.runner.Description;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+import org.junit.runner.notification.RunListener;
+
+import java.io.BufferedWriter;
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.FileWriter;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.io.PrintWriter;
+
+import org.apache.commons.lang.exception.ExceptionUtils;
+//import org.apache.hadoop.hdfs.qjournal.server.JournalNode;
+//import org.apache.hadoop.hdfs.server.namenode.NameNode;
+//import org.apache.hadoop.hdfs.server.datanode.DataNode;
+
+public class MyRunListener extends RunListener {
+
+    public String controllerRootDir = "/root/parameter_test_controller/";
+    public String resultDirName = controllerRootDir + "shared/test_results/";
+    public String result = "";
+    public String SEPERATOR = "@@@";
+    public String failureMessage = "";
+    public String stackTrace = "";
+    public String testName = "";
+    public MyRunListener() {
+        System.out.println("[msx] Creation of Run Listener...");
+    }
+
+/*    public void reset() {
+        try {
+            BufferedReader reader = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/componentHasStopped")));
+            String str = reader.readLine();
+            int componentHasStoppedDefault = Integer.valueOf(str);
+	    int restartPerformedDefault = 0;
+            reader.close();
+	    NameNode.componentHasStopped = componentHasStoppedDefault;
+	    DataNode.componentHasStopped = componentHasStoppedDefault;
+	    JournalNode.componentHasStopped = componentHasStoppedDefault;
+
+	    NameNode.restartPerformed = restartPerformedDefault;
+	    DataNode.restartPerformed = restartPerformedDefault;
+	    JournalNode.restartPerformed = restartPerformedDefault;
+            
+	    System.out.println("[msx] componentHasStopped has been reset to " + componentHasStoppedDefault);
+	    System.out.println("[msx] restartPerformedDefault has been reset to " + restartPerformedDefault);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }        
+    }
+*/
+    public void testStarted(Description description) throws java.lang.Exception {
+	result = "1"; // clean up
+        failureMessage = "none";
+        stackTrace = "none";
+        testName = description.getClassName() + "#" + description.getMethodName();
+        System.out.println("[msx] test Started " + testName);
+    }
+ 
+    public void testFinished(Description description) throws java.lang.Exception {
+        System.out.println("[msx] test Finished " + testName + " test result = " + result);
+        BufferedWriter writer = new BufferedWriter(new FileWriter(resultDirName + testName)); 
+        writer.write(testName + SEPERATOR + result + SEPERATOR + failureMessage + SEPERATOR + stackTrace + SEPERATOR);
+        writer.flush();
+        writer.close();
+//        reset();
+    }
+ 
+    public void testFailure(Failure failure) throws java.lang.Exception {
+        result = "-1";
+        failureMessage = failure.getMessage();
+        stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+        System.out.println("[msx] testFailure " + testName + " test result = " + result);
+    }
+ 
+    public void testIgnored(Description description) throws java.lang.Exception {
+        result = "0";
+        System.out.println("[msx] test Ignored " + testName);
+    }
+     
+    public void testAssumptionFailure(Failure failure) {
+        try {
+            result = "-2";
+            String failureMessage = failure.getMessage();
+            String stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+            System.out.println("[msx] testAssumptionFailure " + testName + " test result = " + result);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }
+    }
+    
+    // Called before any tests have been run.
+    public void testRunStarted(Description description) throws java.lang.Exception {
+        System.out.println("[msx] testRunStarted " + description.testCount());
+    }
+ 
+    // Called when all tests have finished
+    public void testRunFinished(Result result) throws java.lang.Exception {
+        System.out.println("[msx] testRunFinished " + result.getRunCount());
+    }
+}
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/fs/TestXAttr.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/fs/TestXAttr.java
--- ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/fs/TestXAttr.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/fs/TestXAttr.java	2020-01-01 13:19:04.626298505 -0600
@@ -33,6 +33,7 @@
   
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     byte[] value = {0x31, 0x32, 0x33};
     XATTR = new XAttr.Builder()
       .setName("name")
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java
--- ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java	2020-01-01 13:19:04.626298505 -0600
@@ -75,6 +75,7 @@
 
   @BeforeClass
   public static void setupClass() throws Exception {
+System.out.println("[msx] before_class");
     GenericTestUtils.setLogLevel(RequestHedgingProxyProvider.LOG, Level.TRACE);
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java
--- ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java	2020-01-01 13:19:04.626298505 -0600
@@ -63,6 +63,7 @@
 
   @BeforeClass
   public static void setupClass() throws Exception {
+System.out.println("[msx] before_class");
     GenericTestUtils.setLogLevel(RequestHedgingProxyProvider.LOG, Level.TRACE);
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java
--- ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java	2020-01-01 13:19:04.626298505 -0600
@@ -64,6 +64,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     listenSocket = new ServerSocket();
     listenSocket.bind(null);
     bindAddr = NetUtils.getHostPortString(
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml
--- ./hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml	2020-01-01 13:35:32.969900256 -0600
@@ -43,6 +43,14 @@
 
   <dependencies>
     <dependency>
+      <groupId>org.apache.maven.surefire</groupId>
+      <artifactId>surefire-logger-api</artifactId>
+      <version>3.0.0-M4</version>
+      <!-- to get around bug https://github.com/junit-team/junit5/issues/1367 -->
+      <scope>test</scope>
+      <!--<optional>true</optional>-->
+    </dependency>
+    <dependency>
       <groupId>junit</groupId>
       <artifactId>junit</artifactId>
       <scope>test</scope>
@@ -131,7 +139,8 @@
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-hdfs</artifactId>
-      <scope>compile</scope>
+      <scope>provided</scope>
+      <!--<systemPath>/root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-3.1.2.jar</systemPath>-->
       <exclusions>
         <exclusion>
           <groupId>commons-cli</groupId>
@@ -254,6 +263,7 @@
       <plugin>
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-surefire-plugin</artifactId>
+	<version>3.0.0-M4</version>
         <configuration>
           <threadCount>1</threadCount>
           <forkedProcessTimeoutInSeconds>600</forkedProcessTimeoutInSeconds>
@@ -264,7 +274,8 @@
           <properties>
             <property>
               <name>listener</name>
-              <value>org.apache.hadoop.test.TimedOutTestsListener</value>
+              <!--<value>org.apache.hadoop.test.TimedOutTestsListener</value>-->
+              <value>MyRunListener</value>
             </property>
           </properties>
           <excludes>
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/MyRunListener.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/MyRunListener.java
--- ./hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/MyRunListener.java	1969-12-31 18:00:00.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/MyRunListener.java	2020-01-01 13:50:29.664055252 -0600
@@ -0,0 +1,108 @@
+import org.junit.runner.notification.*;
+import org.junit.runner.Description;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+import org.junit.runner.notification.RunListener;
+
+import java.io.BufferedWriter;
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.FileWriter;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.io.PrintWriter;
+
+import org.apache.commons.lang.exception.ExceptionUtils;
+import org.apache.hadoop.hdfs.qjournal.server.JournalNode;
+import org.apache.hadoop.hdfs.server.namenode.NameNode;
+import org.apache.hadoop.hdfs.server.datanode.DataNode;
+
+public class MyRunListener extends RunListener {
+
+    public String controllerRootDir = "/root/parameter_test_controller/";
+    public String resultDirName = controllerRootDir + "shared/test_results/";
+    public String result = "";
+    public String SEPERATOR = "@@@";
+    public String failureMessage = "";
+    public String stackTrace = "";
+    public String testName = "";
+    public MyRunListener() {
+        System.out.println("[msx] Creation of Run Listener...");
+    }
+
+    public void reset() {
+        try {
+            BufferedReader reader = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/componentHasStopped")));
+            String str = reader.readLine();
+            int componentHasStoppedDefault = Integer.valueOf(str);
+	    int restartPerformedDefault = 0;
+            reader.close();
+	    NameNode.componentHasStopped = componentHasStoppedDefault;
+	    DataNode.componentHasStopped = componentHasStoppedDefault;
+	    JournalNode.componentHasStopped = componentHasStoppedDefault;
+
+	    NameNode.restartPerformed = restartPerformedDefault;
+	    DataNode.restartPerformed = restartPerformedDefault;
+	    JournalNode.restartPerformed = restartPerformedDefault;
+            
+	    System.out.println("[msx] componentHasStopped has been reset to " + componentHasStoppedDefault);
+	    System.out.println("[msx] restartPerformedDefault has been reset to " + restartPerformedDefault);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }        
+    }
+ 
+    public void testStarted(Description description) throws java.lang.Exception {
+	result = "1"; // clean up
+        failureMessage = "none";
+        stackTrace = "none";
+        testName = description.getClassName() + "#" + description.getMethodName();
+        System.out.println("[msx] test Started " + testName);
+    }
+ 
+    public void testFinished(Description description) throws java.lang.Exception {
+        System.out.println("[msx] test Finished " + testName + " test result = " + result);
+        BufferedWriter writer = new BufferedWriter(new FileWriter(resultDirName + testName)); 
+        writer.write(testName + SEPERATOR + result + SEPERATOR + failureMessage + SEPERATOR + stackTrace + SEPERATOR);
+        writer.flush();
+        writer.close();
+        reset();
+    }
+ 
+    public void testFailure(Failure failure) throws java.lang.Exception {
+        result = "-1";
+        failureMessage = failure.getMessage();
+        stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+        System.out.println("[msx] testFailure " + testName + " test result = " + result);
+    }
+ 
+    public void testIgnored(Description description) throws java.lang.Exception {
+        result = "0";
+        System.out.println("[msx] test Ignored " + testName);
+    }
+     
+    public void testAssumptionFailure(Failure failure) {
+        try {
+            result = "-2";
+            String failureMessage = failure.getMessage();
+            String stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+            System.out.println("[msx] testAssumptionFailure " + testName + " test result = " + result);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }
+    }
+    
+    // Called before any tests have been run.
+    public void testRunStarted(Description description) throws java.lang.Exception {
+        System.out.println("[msx] testRunStarted " + description.testCount());
+    }
+ 
+    // Called when all tests have finished
+    public void testRunFinished(Result result) throws java.lang.Exception {
+        System.out.println("[msx] testRunFinished " + result.getRunCount());
+    }
+}
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServerWebServer.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServerWebServer.java
--- ./hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServerWebServer.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServerWebServer.java	2020-01-01 13:19:04.630298568 -0600
@@ -48,6 +48,7 @@
 
   @BeforeClass
   public static void beforeClass() throws Exception {
+System.out.println("[msx] before_class");
     File homeDir = GenericTestUtils.getTestDir();
     File confDir = new File(homeDir, "etc/hadoop");
     File logsDir = new File(homeDir, "logs");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-native-client/pom.xml /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-native-client/pom.xml
--- ./hadoop-hdfs-project/hadoop-hdfs-native-client/pom.xml	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-native-client/pom.xml	2020-01-01 13:19:04.634298631 -0600
@@ -76,6 +76,19 @@
 
   <build>
     <plugins>
+  <plugin>
+    <groupId>org.apache.maven.plugins</groupId>
+    <artifactId>maven-surefire-plugin</artifactId>
+    <version>3.0.0-M4</version>
+    <configuration>
+      <properties>
+        <property>
+          <name>listener</name>
+          <value>MyRunListener</value>
+        </property>
+      </properties>
+    </configuration>
+  </plugin>
       <plugin>
         <groupId>org.apache.rat</groupId>
         <artifactId>apache-rat-plugin</artifactId>
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/test/TestFuseDFS.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/test/TestFuseDFS.java
--- ./hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/test/TestFuseDFS.java	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/test/TestFuseDFS.java	2020-01-01 13:19:04.634298631 -0600
@@ -234,6 +234,7 @@
 
   @BeforeClass
   public static void startUp() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     r = Runtime.getRuntime();
     mountPoint = System.getProperty("build.test") + "/mnt";
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-nfs/pom.xml /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/pom.xml
--- ./hadoop-hdfs-project/hadoop-hdfs-nfs/pom.xml	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/pom.xml	2020-01-01 13:37:50.520071590 -0600
@@ -53,7 +53,8 @@
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-hdfs</artifactId>
-      <scope>compile</scope>
+      <scope>provided</scope>
+      <!--<systemPath>/root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-3.1.2.jar</systemPath>-->
     </dependency>
     <dependency>
       <groupId>org.apache.hadoop</groupId>
@@ -174,7 +175,25 @@
       <scope>test</scope>
     </dependency>
   </dependencies>
-
+ 
+  <build>
+    <plugins>
+    <plugin>
+    <groupId>org.apache.maven.plugins</groupId>
+    <artifactId>maven-surefire-plugin</artifactId>
+    <version>3.0.0-M4</version>
+    <configuration>
+      <properties>
+        <property>
+          <name>listener</name>
+          <value>MyRunListener</value>
+        </property>
+      </properties>
+    </configuration>
+  </plugin>
+   </plugins>
+  </build>
+ 
   <profiles>
     <profile>
       <id>dist</id>
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/MyRunListener.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/MyRunListener.java
--- ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/MyRunListener.java	1969-12-31 18:00:00.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/MyRunListener.java	2020-01-01 13:50:41.480241780 -0600
@@ -0,0 +1,108 @@
+import org.junit.runner.notification.*;
+import org.junit.runner.Description;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+import org.junit.runner.notification.RunListener;
+
+import java.io.BufferedWriter;
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.FileWriter;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.io.PrintWriter;
+
+import org.apache.commons.lang.exception.ExceptionUtils;
+import org.apache.hadoop.hdfs.qjournal.server.JournalNode;
+import org.apache.hadoop.hdfs.server.namenode.NameNode;
+import org.apache.hadoop.hdfs.server.datanode.DataNode;
+
+public class MyRunListener extends RunListener {
+
+    public String controllerRootDir = "/root/parameter_test_controller/";
+    public String resultDirName = controllerRootDir + "shared/test_results/";
+    public String result = "";
+    public String SEPERATOR = "@@@";
+    public String failureMessage = "";
+    public String stackTrace = "";
+    public String testName = "";
+    public MyRunListener() {
+        System.out.println("[msx] Creation of Run Listener...");
+    }
+
+    public void reset() {
+        try {
+            BufferedReader reader = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/componentHasStopped")));
+            String str = reader.readLine();
+            int componentHasStoppedDefault = Integer.valueOf(str);
+	    int restartPerformedDefault = 0;
+            reader.close();
+	    NameNode.componentHasStopped = componentHasStoppedDefault;
+	    DataNode.componentHasStopped = componentHasStoppedDefault;
+	    JournalNode.componentHasStopped = componentHasStoppedDefault;
+
+	    NameNode.restartPerformed = restartPerformedDefault;
+	    DataNode.restartPerformed = restartPerformedDefault;
+	    JournalNode.restartPerformed = restartPerformedDefault;
+            
+	    System.out.println("[msx] componentHasStopped has been reset to " + componentHasStoppedDefault);
+	    System.out.println("[msx] restartPerformedDefault has been reset to " + restartPerformedDefault);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }        
+    }
+ 
+    public void testStarted(Description description) throws java.lang.Exception {
+	result = "1"; // clean up
+        failureMessage = "none";
+        stackTrace = "none";
+        testName = description.getClassName() + "#" + description.getMethodName();
+        System.out.println("[msx] test Started " + testName);
+    }
+ 
+    public void testFinished(Description description) throws java.lang.Exception {
+        System.out.println("[msx] test Finished " + testName + " test result = " + result);
+        BufferedWriter writer = new BufferedWriter(new FileWriter(resultDirName + testName)); 
+        writer.write(testName + SEPERATOR + result + SEPERATOR + failureMessage + SEPERATOR + stackTrace + SEPERATOR);
+        writer.flush();
+        writer.close();
+        reset();
+    }
+ 
+    public void testFailure(Failure failure) throws java.lang.Exception {
+        result = "-1";
+        failureMessage = failure.getMessage();
+        stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+        System.out.println("[msx] testFailure " + testName + " test result = " + result);
+    }
+ 
+    public void testIgnored(Description description) throws java.lang.Exception {
+        result = "0";
+        System.out.println("[msx] test Ignored " + testName);
+    }
+     
+    public void testAssumptionFailure(Failure failure) {
+        try {
+            result = "-2";
+            String failureMessage = failure.getMessage();
+            String stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+            System.out.println("[msx] testAssumptionFailure " + testName + " test result = " + result);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }
+    }
+    
+    // Called before any tests have been run.
+    public void testRunStarted(Description description) throws java.lang.Exception {
+        System.out.println("[msx] testRunStarted " + description.testCount());
+    }
+ 
+    // Called when all tests have finished
+    public void testRunFinished(Result result) throws java.lang.Exception {
+        System.out.println("[msx] testRunFinished " + result.getRunCount());
+    }
+}
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestClientAccessPrivilege.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestClientAccessPrivilege.java
--- ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestClientAccessPrivilege.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestClientAccessPrivilege.java	2020-01-01 13:19:04.638298694 -0600
@@ -52,6 +52,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
 
     String currentUser = System.getProperty("user.name");
     config.set(DefaultImpersonationProvider.getTestProvider()
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestNfs3HttpServer.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestNfs3HttpServer.java
--- ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestNfs3HttpServer.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestNfs3HttpServer.java	2020-01-01 13:19:04.638298694 -0600
@@ -45,6 +45,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     conf.set(DFSConfigKeys.DFS_HTTP_POLICY_KEY,
         HttpConfig.Policy.HTTP_AND_HTTPS.name());
     conf.set(NfsConfigKeys.NFS_HTTP_ADDRESS_KEY, "localhost:0");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestReaddir.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestReaddir.java
--- ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestReaddir.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestReaddir.java	2020-01-01 13:19:04.638298694 -0600
@@ -61,6 +61,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
     String currentUser = System.getProperty("user.name");
     config.set(
             DefaultImpersonationProvider.getTestProvider().
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestRpcProgramNfs3.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestRpcProgramNfs3.java
--- ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestRpcProgramNfs3.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestRpcProgramNfs3.java	2020-01-01 13:19:04.638298694 -0600
@@ -123,6 +123,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
     String currentUser = System.getProperty("user.name");
 
     config.set("fs.permissions.umask-mode", "u=rwx,g=,o=");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestViewfsWithNfs3.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestViewfsWithNfs3.java
--- ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestViewfsWithNfs3.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestViewfsWithNfs3.java	2020-01-01 13:19:04.638298694 -0600
@@ -85,6 +85,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
     String currentUser = System.getProperty("user.name");
 
     config.set("fs.permissions.umask-mode", "u=rwx,g=,o=");
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/pom.xml /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/pom.xml
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/pom.xml	2019-01-23 09:07:50.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/pom.xml	2020-01-01 13:30:14.580874244 -0600
@@ -53,6 +53,7 @@
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-hdfs</artifactId>
       <scope>provided</scope>
+      <!--<systemPath>/root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-3.1.2.jar</systemPath>-->
     </dependency>
     <dependency>
       <groupId>org.apache.hadoop</groupId>
@@ -111,6 +112,15 @@
       <plugin>
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-surefire-plugin</artifactId>
+	<version>3.0.0-M4</version>
+        <configuration>
+          <properties>
+            <property>
+              <name>listener</name>
+              <value>MyRunListener</value>
+            </property>
+          </properties>
+    	</configuration>
       </plugin>
       <plugin>
         <groupId>org.apache.maven.plugins</groupId>
@@ -234,4 +244,4 @@
       </plugin>
     </plugins>
   </build>
-</project>
\ No newline at end of file
+</project>
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/MyRunListener.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/MyRunListener.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/MyRunListener.java	1969-12-31 18:00:00.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/MyRunListener.java	2020-01-01 13:50:12.819789353 -0600
@@ -0,0 +1,108 @@
+import org.junit.runner.notification.*;
+import org.junit.runner.Description;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+import org.junit.runner.notification.RunListener;
+
+import java.io.BufferedWriter;
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.FileWriter;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.io.PrintWriter;
+
+import org.apache.commons.lang.exception.ExceptionUtils;
+import org.apache.hadoop.hdfs.qjournal.server.JournalNode;
+import org.apache.hadoop.hdfs.server.namenode.NameNode;
+import org.apache.hadoop.hdfs.server.datanode.DataNode;
+
+public class MyRunListener extends RunListener {
+
+    public String controllerRootDir = "/root/parameter_test_controller/";
+    public String resultDirName = controllerRootDir + "shared/test_results/";
+    public String result = "";
+    public String SEPERATOR = "@@@";
+    public String failureMessage = "";
+    public String stackTrace = "";
+    public String testName = "";
+    public MyRunListener() {
+        System.out.println("[msx] Creation of Run Listener...");
+    }
+
+    public void reset() {
+        try {
+            BufferedReader reader = new BufferedReader(new FileReader(new File(controllerRootDir + "shared/componentHasStopped")));
+            String str = reader.readLine();
+            int componentHasStoppedDefault = Integer.valueOf(str);
+	    int restartPerformedDefault = 0;
+            reader.close();
+	    NameNode.componentHasStopped = componentHasStoppedDefault;
+	    DataNode.componentHasStopped = componentHasStoppedDefault;
+	    JournalNode.componentHasStopped = componentHasStoppedDefault;
+
+	    NameNode.restartPerformed = restartPerformedDefault;
+	    DataNode.restartPerformed = restartPerformedDefault;
+	    JournalNode.restartPerformed = restartPerformedDefault;
+            
+	    System.out.println("[msx] componentHasStopped has been reset to " + componentHasStoppedDefault);
+	    System.out.println("[msx] restartPerformedDefault has been reset to " + restartPerformedDefault);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }        
+    }
+ 
+    public void testStarted(Description description) throws java.lang.Exception {
+	result = "1"; // clean up
+        failureMessage = "none";
+        stackTrace = "none";
+        testName = description.getClassName() + "#" + description.getMethodName();
+        System.out.println("[msx] test Started " + testName);
+    }
+ 
+    public void testFinished(Description description) throws java.lang.Exception {
+        System.out.println("[msx] test Finished " + testName + " test result = " + result);
+        BufferedWriter writer = new BufferedWriter(new FileWriter(resultDirName + testName)); 
+        writer.write(testName + SEPERATOR + result + SEPERATOR + failureMessage + SEPERATOR + stackTrace + SEPERATOR);
+        writer.flush();
+        writer.close();
+        reset();
+    }
+ 
+    public void testFailure(Failure failure) throws java.lang.Exception {
+        result = "-1";
+        failureMessage = failure.getMessage();
+        stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+        System.out.println("[msx] testFailure " + testName + " test result = " + result);
+    }
+ 
+    public void testIgnored(Description description) throws java.lang.Exception {
+        result = "0";
+        System.out.println("[msx] test Ignored " + testName);
+    }
+     
+    public void testAssumptionFailure(Failure failure) {
+        try {
+            result = "-2";
+            String failureMessage = failure.getMessage();
+            String stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+            System.out.println("[msx] testAssumptionFailure " + testName + " test result = " + result);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }
+    }
+    
+    // Called before any tests have been run.
+    public void testRunStarted(Description description) throws java.lang.Exception {
+        System.out.println("[msx] testRunStarted " + description.testCount());
+    }
+ 
+    // Called when all tests have finished
+    public void testRunFinished(Result result) throws java.lang.Exception {
+        System.out.println("[msx] testRunFinished " + result.getRunCount());
+    }
+}
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractAppend.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractAppend.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractAppend.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractAppend.java	2020-01-01 13:19:04.646298820 -0600
@@ -29,6 +29,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractConcat.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractConcat.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractConcat.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractConcat.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
     // perform a simple operation on the cluster to verify it is up
     RouterHDFSContract.getFileSystem().getDefaultBlockSize(new Path("/"));
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractCreate.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractCreate.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractCreate.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractCreate.java	2020-01-01 13:19:04.646298820 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractDelete.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractDelete.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractDelete.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractDelete.java	2020-01-01 13:19:04.646298820 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractGetFileStatus.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractGetFileStatus.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractGetFileStatus.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractGetFileStatus.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractMkdir.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractMkdir.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractMkdir.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractMkdir.java	2020-01-01 13:19:04.646298820 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractOpen.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractOpen.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractOpen.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractOpen.java	2020-01-01 13:19:04.646298820 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRename.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRename.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRename.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRename.java	2020-01-01 13:19:04.646298820 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRootDirectory.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRootDirectory.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRootDirectory.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRootDirectory.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSeek.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSeek.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSeek.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSeek.java	2020-01-01 13:19:04.646298820 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSetTimes.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSetTimes.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSetTimes.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSetTimes.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractAppend.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractAppend.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractAppend.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractAppend.java	2020-01-01 13:19:04.646298820 -0600
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractConcat.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractConcat.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractConcat.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractConcat.java	2020-01-01 13:19:04.646298820 -0600
@@ -35,6 +35,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
     // perform a simple operation on the cluster to verify it is up
     RouterWebHDFSContract.getFileSystem().getDefaultBlockSize(new Path("/"));
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractCreate.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractCreate.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractCreate.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractCreate.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractDelete.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractDelete.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractDelete.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractDelete.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractMkdir.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractMkdir.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractMkdir.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractMkdir.java	2020-01-01 13:19:04.646298820 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractOpen.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractOpen.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractOpen.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractOpen.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRename.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRename.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRename.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRename.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRootDirectory.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRootDirectory.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRootDirectory.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRootDirectory.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractSeek.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractSeek.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractSeek.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractSeek.java	2020-01-01 13:19:04.646298820 -0600
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/resolver/TestNamenodeResolver.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/resolver/TestNamenodeResolver.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/resolver/TestNamenodeResolver.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/resolver/TestNamenodeResolver.java	2020-01-01 13:19:04.646298820 -0600
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void create() throws Exception {
+System.out.println("[msx] before_class");
 
     Configuration conf = getStateStoreConfiguration();
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableNameservices.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableNameservices.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableNameservices.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableNameservices.java	2020-01-01 13:19:04.646298820 -0600
@@ -68,6 +68,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     // Build and start a federated cluster
     cluster = new StateStoreDFSCluster(false, 2);
     Configuration routerConf = new RouterConfigBuilder()
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableRouterQuota.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableRouterQuota.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableRouterQuota.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableRouterQuota.java	2020-01-01 13:19:04.646298820 -0600
@@ -40,6 +40,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     // Build and start a router
     router = new Router();
     Configuration routerConf = new RouterConfigBuilder()
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdminCLI.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdminCLI.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdminCLI.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdminCLI.java	2020-01-01 13:19:04.646298820 -0600
@@ -76,6 +76,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new StateStoreDFSCluster(false, 1);
     // Build and start a router with State Store + admin + RPC
     Configuration conf = new RouterConfigBuilder()
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java	2020-01-01 13:19:04.646298820 -0600
@@ -82,6 +82,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new StateStoreDFSCluster(false, 1);
     // Build and start a router with State Store + admin + RPC
     Configuration conf = new RouterConfigBuilder()
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouter.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouter.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouter.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouter.java	2020-01-01 13:19:04.646298820 -0600
@@ -51,6 +51,7 @@
 
   @BeforeClass
   public static void create() throws IOException {
+System.out.println("[msx] before_class");
     // Basic configuration without the state store
     conf = new Configuration();
     // 1 sec cache refresh
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java	2020-01-01 13:19:04.646298820 -0600
@@ -62,6 +62,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
 
     // Build and start a federated cluster
     cluster = new StateStoreDFSCluster(false, 1);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterNamenodeHeartbeat.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterNamenodeHeartbeat.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterNamenodeHeartbeat.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterNamenodeHeartbeat.java	2020-01-01 13:19:04.646298820 -0600
@@ -53,6 +53,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
 
     cluster = new MiniRouterDFSCluster(true, 2);
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java	2020-01-01 13:19:04.646298820 -0600
@@ -161,6 +161,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new MiniRouterDFSCluster(false, 2);
     // We need 6 DNs to test Erasure Coding with RS-6-3-64k
     cluster.setNumDatanodesPerNameservice(6);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterSafemode.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterSafemode.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterSafemode.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterSafemode.java	2020-01-01 13:19:04.646298820 -0600
@@ -56,6 +56,7 @@
 
   @BeforeClass
   public static void create() throws IOException {
+System.out.println("[msx] before_class");
     // Wipe state store
     deleteStateStore();
     // Configuration that supports the state store
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFile.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFile.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFile.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFile.java	2020-01-01 13:19:04.646298820 -0600
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = getStateStoreConfiguration(StateStoreFileImpl.class);
     getStateStore(conf);
   }
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFileSystem.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFileSystem.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFileSystem.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFileSystem.java	2020-01-01 13:19:04.646298820 -0600
@@ -37,6 +37,7 @@
 
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = FederationStateStoreTestUtils
         .getStateStoreConfiguration(StateStoreFileSystemImpl.class);
     conf.set(StateStoreFileSystemImpl.FEDERATION_STORE_FS_PATH,
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreZK.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreZK.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreZK.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreZK.java	2020-01-01 13:19:04.646298820 -0600
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     curatorTestingServer = new TestingServer();
     curatorTestingServer.start();
     String connectString = curatorTestingServer.getConnectString();
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreBase.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreBase.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreBase.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreBase.java	2020-01-01 13:19:04.646298820 -0600
@@ -50,6 +50,7 @@
 
   @BeforeClass
   public static void createBase() throws IOException, InterruptedException {
+System.out.println("[msx] before_class");
 
     conf = getStateStoreConfiguration();
 
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMembershipState.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMembershipState.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMembershipState.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMembershipState.java	2020-01-01 13:19:04.646298820 -0600
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void create() {
+System.out.println("[msx] before_class");
     // Reduce expirations to 5 seconds
     getConf().setLong(
         RBFConfigKeys.FEDERATION_STORE_MEMBERSHIP_EXPIRATION_MS,
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMountTable.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMountTable.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMountTable.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMountTable.java	2020-01-01 13:19:04.646298820 -0600
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void create() throws IOException {
+System.out.println("[msx] before_class");
     nameservices = new ArrayList<>();
     nameservices.add(NAMESERVICES[0]);
     nameservices.add(NAMESERVICES[1]);
diff -ruN ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreRouterState.java /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreRouterState.java
--- ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreRouterState.java	2019-01-23 09:07:46.000000000 -0600
+++ /root/hadoop-3.1.2-src-reconf/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreRouterState.java	2020-01-01 13:19:04.646298820 -0600
@@ -50,6 +50,7 @@
 
   @BeforeClass
   public static void create() {
+System.out.println("[msx] before_class");
     // Reduce expirations to 5 seconds
     getConf().setTimeDuration(
         RBFConfigKeys.FEDERATION_STORE_ROUTER_EXPIRATION_MS,
