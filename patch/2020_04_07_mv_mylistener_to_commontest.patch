diff -ruN /hadoop-3.1.2-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configured.java ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configured.java
--- /hadoop-3.1.2-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configured.java	2019-01-23 15:07:45.000000000 +0000
+++ ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configured.java	2020-03-24 05:28:31.000000000 +0000
@@ -24,7 +24,7 @@
 /** Base class for things that may be configured with a {@link Configuration}. */
 @InterfaceAudience.Public
 @InterfaceStability.Stable
-public class Configured implements Configurable {
+public class Configured extends ReconfAgent implements Configurable {
 
   private Configuration conf;
 
@@ -49,5 +49,4 @@
   public Configuration getConf() {
     return conf;
   }
-
 }
diff -ruN /hadoop-3.1.2-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java
--- /hadoop-3.1.2-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java	1970-01-01 00:00:00.000000000 +0000
+++ ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java	2020-03-24 05:28:31.000000000 +0000
@@ -0,0 +1,144 @@
+package org.apache.hadoop.conf;
+
+import java.io.*;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class ReconfAgent {
+    // msx
+    private static final Logger LOG = LoggerFactory.getLogger(Configured.class);
+    private static final int RP_MODE_INSTANCE = -1; // set v2 to a single instance of the specified component throughout a test
+    private static final int RP_MODE_COMPONENT = -2; // set v2 to all instances for the specified component
+    //private static final String RP_MODE_RECONF = "1"; // set v2 to a single life cycle of a single instance of the specified component
+    private static final String reconf_systemRootDir = "/root/parameter_test_controller/";
+
+    // variables have to be reset for each test
+    public static boolean reconf_instanceWithV2Alive = false;
+    public static int reconf_instanceWithV2HC = -1;
+    public static int reconf_init_point_index = 0;
+
+    protected int reconf_msxPort = 0; // per object
+
+    private static String reconf_vvmode = "";
+    protected static String reconf_parameter = ""; // double check in start/stop
+    private static String reconf_component = "";
+    private static String reconf_v1 = "";
+    private static String reconf_v2 = "";
+    protected static String reconf_point = ""; // synchronized for locking
+    private static int reconf_point_int = 0; 
+
+    private static void loadSharedVariables() {
+        try {
+            BufferedReader reader;
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_vvmode")));
+            reconf_vvmode = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_parameter")));
+            reconf_parameter = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_component")));
+            reconf_component = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_v1")));
+            reconf_v1 = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_v2")));
+            reconf_v2 = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_point")));
+            reconf_point = reader.readLine();
+            reader.close();
+            reconf_point_int = Integer.valueOf(reconf_point);
+
+            if (!reconf_vvmode.equals("v1v1") && !reconf_vvmode.equals("v2v2") && !reconf_vvmode.equals("v1v2") && !reconf_vvmode.equals("none")) {
+                LOG.info("[msx-restart] Error : wrong value of reconf_vvmode " + reconf_vvmode);
+                System.exit(1);
+            }
+        } catch (Exception e) {
+            LOG.info("[msx-restart] Error : loadSharedVariables");
+            e.printStackTrace();
+        }
+    }
+
+    static {
+        loadSharedVariables();
+    }
+
+    public void performReconf(String component, Configuration myConf) {
+      if (reconf_vvmode.equals("none")) {
+          LOG.info("[msx-restart] " + component + " init, vvmode is none, do nothing");
+      }
+
+      if (reconf_vvmode.equals("v1v1")) {
+          myConf.set(reconf_parameter, reconf_v1);
+          LOG.info("[msx-restart] " + component + " init, parameter=" + reconf_parameter + " vvmode=" + reconf_vvmode + " parameter=v1=" + reconf_v1);
+      }
+
+      if ((reconf_vvmode.equals("v2v2"))) {
+          if (this == null) {
+              LOG.info("[msx-restart] this == null");
+          }
+          if (myConf == null) {
+              LOG.info("[msx-restart] myConf == null");
+          }
+          if (reconf_parameter == null) {
+              LOG.info("[msx-restart] reconf_parameter == null");
+          }
+          if (reconf_v2 == null) {
+              LOG.info("[msx-restart] reconf_v2 == null");
+          }
+          myConf.set(reconf_parameter, reconf_v2);
+          LOG.info("[msx-restart] " + component + " init, parameter=" + reconf_parameter + " vvmode=" + reconf_vvmode + " parameter=v2=" + reconf_v2);
+      }
+
+      if (reconf_vvmode.equals("v1v2")) { // reconfiguration injection
+          try {
+              synchronized(reconf_point) {
+                  if (reconf_component.equals(component)) {
+                      if (reconf_point_int == RP_MODE_COMPONENT) {
+                          myConf.set(reconf_parameter, reconf_v2);
+                          LOG.info("[msx-restart] " + component + " init, perform Component-Wide v1v2 reconf " + reconf_point +  " for " + component + ". " +
+                              "Assign " + reconf_parameter + " as v2 value " + reconf_v2);
+                      } else if (reconf_point_int == RP_MODE_INSTANCE) {
+                          if (reconf_instanceWithV2Alive == false) {
+                                reconf_instanceWithV2Alive = true;
+                                reconf_instanceWithV2HC = this.hashCode();
+                                myConf.set(reconf_parameter, reconf_v2);
+                                LOG.info("[msx-restart] " + component + " init, perform Instance-Wide v1v2 reconf " + reconf_point +  " for " + component + ". " +
+                                    "Assign " + reconf_parameter + " as v2 value " + reconf_v2);
+                                LOG.info("[msx-restart] switch instanceWithV2Alive to true and record instanceWithV2HC as " + reconf_instanceWithV2HC);
+                            } else { // the instance configured with v2 is still alive
+                                myConf.set(reconf_parameter, reconf_v1);
+                                LOG.info("[msx-restart] " + component + " init, the instance configured with v2 is still alive. " +
+                                    "Assign " + reconf_parameter + " as v1 value " + reconf_v1);
+                            }
+                      } else {
+                          reconf_init_point_index ++;
+                          if (reconf_point_int == reconf_init_point_index) {
+                              myConf.set(reconf_parameter, reconf_v2);
+                              LOG.info("[msx-restart] " + component + " init, perform Reconf-Wide v1v2 reconf " + reconf_point +  " for " + component + ". " +
+                                  "Assign " + reconf_parameter + " as v2 value " + reconf_v2);
+                          } else {
+                              myConf.set(reconf_parameter, reconf_v1);
+                              LOG.info("[msx-restart] " + component + " init, reconf_init_point_index is " + reconf_init_point_index + " but reconf_point is " + reconf_point + ". " +
+                                  "Assign " + reconf_parameter + " as v1 value " + reconf_v1);
+                          }
+                      }
+                  } else { // for other component instances, just configure it to be v1
+                      myConf.set(reconf_parameter, reconf_v1);
+                      LOG.info("[msx-restart] " + component + " init, I'm not the component concerned for this reconf test. " +
+                          "Assign " + reconf_parameter + " as v1 value " + reconf_v1);
+                  }
+              }
+          } catch (Exception e) {
+              LOG.info("[msx-restart] Error happened during performReconf");
+              System.exit(1);
+          }
+      }
+    }
+}
diff -ruN /hadoop-3.1.2-src/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/MyRunListener.java ./hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/MyRunListener.java
--- /hadoop-3.1.2-src/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/MyRunListener.java	1970-01-01 00:00:00.000000000 +0000
+++ ./hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/MyRunListener.java	2020-04-08 02:19:40.090002460 +0000
@@ -0,0 +1,152 @@
+package org.apache.hadoop.test;
+
+import org.junit.runner.notification.*;
+import org.junit.runner.Description;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+import org.junit.runner.notification.RunListener;
+
+import java.io.BufferedWriter;
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.FileWriter;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.io.PrintWriter;
+import java.text.SimpleDateFormat;
+import java.util.*;
+
+import org.apache.commons.lang.exception.ExceptionUtils;
+
+public class MyRunListener extends RunListener {
+
+    public String controllerRootDir = "/root/parameter_test_controller/";
+    public String resultDirName = controllerRootDir + "shared/test_results/";
+    public String warnDirName = controllerRootDir + "shared/warn_results/";
+    public String SEPERATOR = "@@@";
+    public String globalTestName = "";
+    public int unitTestCounterInClass = 0;
+    
+    public MyRunListener() {
+        System.out.println("[msx] Creation of Run Listener...");
+    }
+
+    public void reset() {
+        try {
+	    ;
+        } catch(Exception e) {
+            e.printStackTrace();
+        }        
+    }
+ 
+    private void writeFile(String testName, String failureMessage, String stackTrace, String result) throws IOException {
+        System.out.println("[msx] writeFile testName = " + testName);
+        File theFile = null;
+        if (testName.equals("")) {
+            Date date = new Date();
+            SimpleDateFormat formatter = new SimpleDateFormat("yyyy-MM-dd-HH-mm-ss");
+            String dateTime = "Warn-" + formatter.format(date);
+            theFile = new File(warnDirName + dateTime);
+        } else {
+            theFile = new File(resultDirName + testName);
+        }
+
+        if (!theFile.exists()) {
+            BufferedWriter writer = new BufferedWriter(new FileWriter(theFile)); 
+            writer.write(testName + SEPERATOR + result + SEPERATOR + failureMessage + SEPERATOR + stackTrace + SEPERATOR);
+            writer.flush();
+            writer.close();
+        } else {
+            System.out.println("[msx] Info : file existed " + theFile);
+        }
+    }
+
+    private String getTestName(String className, String methodName) throws java.lang.Exception {
+        if (className == null || methodName == null || className.equals("") ||  methodName.equals("")) {
+            if (!globalTestName.equals("") && !globalTestName.equals("#")) {
+                System.out.println("[msx-result] Warn : using globalTestName " + globalTestName);
+                return globalTestName;
+            } else {
+                System.out.println("[msx-result] Error : unable to obtain test name!");
+                return "";
+            } 
+        }
+        return className + "#" + methodName;
+    }
+
+    private void succeed(String testName, Description description) throws java.lang.Exception {
+        String failureMessage = "none";
+        String stackTrace = "none";
+        String result = "1";
+        writeFile(testName, failureMessage, stackTrace, result);
+        System.out.println("[msx] succeed");
+        reset();
+    }
+
+    private void failed(String testName, Failure failure) throws java.lang.Exception {
+        String failureMessage = failure.getMessage();
+        String stackTrace = ExceptionUtils.getStackTrace(failure.getException());
+        String result = "-1";
+        writeFile(testName, failureMessage, stackTrace, result);
+        System.out.println("[msx] failed");
+        System.out.println("[msx] failureMessage: " + failureMessage);
+        System.out.println("[msx] stackTrace: " + stackTrace);
+        reset();
+    }
+    
+    public void testStarted(Description description) throws java.lang.Exception {
+        globalTestName = description.getClassName() + "#" + description.getMethodName();
+        System.out.println("[msx] test Started " + globalTestName);
+        if (unitTestCounterInClass > 0) { // perform reset
+            System.out.println("[msx] perform reset as unitTestCounterInClass " + unitTestCounterInClass + " is larger than zero");
+            reset();
+        } else {
+            System.out.println("[msx] unitTestCounterInClass = " + unitTestCounterInClass);
+        }
+        unitTestCounterInClass++;
+    }
+
+    public void testFinished(Description description) throws java.lang.Exception {
+        String testName = getTestName(description.getClassName(), description.getMethodName());
+        System.out.println("[msx] test Finished " + testName);
+        succeed(testName, description);
+    }
+    
+    public void testIgnored(Description description) throws java.lang.Exception {
+        String testName = getTestName(description.getClassName(), description.getMethodName());
+        System.out.println("[msx] test Ignored " + testName);
+        succeed(testName, description);
+    }
+     
+    public void testFailure(Failure failure) throws java.lang.Exception {
+        Description description = failure.getDescription();
+        String testName = getTestName(description.getClassName(), description.getMethodName());
+        System.out.println("[msx] test Failure " + testName);
+        failed(testName, failure);
+    }
+ 
+    public void testAssumptionFailure(Failure failure) {
+        try {
+            Description description = failure.getDescription();
+            String testName = getTestName(description.getClassName(), description.getMethodName());
+            System.out.println("[msx] testAssumptionFailure " + testName);
+            failed(testName, failure);
+        } catch(Exception e) {
+            e.printStackTrace();
+        }
+    }
+    
+    // Called before any tests have been run.
+    public void testRunStarted(Description description) throws java.lang.Exception {
+        System.out.println("[msx] all testRunStarted");
+    }
+ 
+    // Called when all tests have finished
+    public void testRunFinished(Result result) throws java.lang.Exception {
+        System.out.println("[msx] all testRunFinished");
+    }
+}
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/pom.xml ./hadoop-hdfs-project/hadoop-hdfs/pom.xml
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/pom.xml	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/pom.xml	2020-04-08 02:20:50.662749762 +0000
@@ -36,6 +36,7 @@
   </properties>
 
   <dependencies>
+
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-annotations</artifactId>
@@ -228,7 +229,8 @@
           <properties>
             <property>
               <name>listener</name>
-              <value>org.apache.hadoop.test.TimedOutTestsListener</value>
+              <value>org.apache.hadoop.test.MyRunListener</value>
+              <!--<value>org.apache.hadoop.test.TimedOutTestsListener</value>-->
             </property>
           </properties>
         </configuration>
@@ -421,9 +423,24 @@
           </filesets>
         </configuration>
       </plugin>
+<!--
+  <plugin>
+    <groupId>org.apache.maven.plugins</groupId>
+    <artifactId>maven-surefire-plugin</artifactId>
+    <version>3.0.0-M4</version>
+    <configuration>
+      <properties>
+        <property>
+          <name>listener</name>
+          <value>MyRunListener</value>
+        </property>
+      </properties>
+    </configuration>
+  </plugin>
+-->
+
     </plugins>
   </build>
-
   <profiles>
     <!-- profile that starts ApacheDS KDC server -->
     <profile>
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java	2020-03-24 05:28:31.000000000 +0000
@@ -59,6 +59,9 @@
 import java.util.HashMap;
 import java.util.Map;
 
+// msx
+import java.io.*;
+import org.apache.hadoop.conf.ReconfAgent;
 /**
  * The JournalNode is a daemon which allows namenodes using
  * the QuorumJournalManager to log and retrieve edits stored
@@ -67,7 +70,7 @@
  * in the quorum protocol.
  */
 @InterfaceAudience.Private
-public class JournalNode implements Tool, Configurable, JournalNodeMXBean {
+public class JournalNode extends ReconfAgent implements Tool, Configurable, JournalNodeMXBean {
   public static final Log LOG = LogFactory.getLog(JournalNode.class);
   private Configuration conf;
   private JournalNodeRpcServer rpcServer;
@@ -149,8 +152,12 @@
 
   @Override
   public void setConf(Configuration conf) {
+    //LOG.info("[msx-restart] JournalNode setConf conf");
     this.conf = conf;
 
+    // msx
+    performReconf("JournalNode", conf);
+
     String journalNodeDir = null;
     Collection<String> nameserviceIds;
 
@@ -211,6 +218,7 @@
    */
   public void start() throws IOException {
     Preconditions.checkState(!isStarted(), "JN already running");
+    //LOG.info("[msx-restart] JournalNode start");
 
     try {
 
@@ -237,6 +245,13 @@
 
       rpcServer = new JournalNodeRpcServer(conf, this);
       rpcServer.start();
+
+      try {
+          this.reconf_msxPort = rpcServer.getRpcServer().getPort();
+          LOG.info("[msx-restart] JournalNode " + this.reconf_msxPort + " start, check after start, " + reconf_parameter + " = " + conf.get(reconf_parameter));
+      } catch (Exception e) {
+          LOG.warn("[msx-restart] " + e.getMessage());
+      }
     } catch (IOException ioe) {
       //Shutdown JournalNode of JournalNodeRpcServer fails to start
       LOG.error("Failed to start JournalNode.", ioe);
@@ -266,6 +281,20 @@
    * should indicate an error)
    */
   public void stop(int rc) {
+    try {
+        Configuration conf = this.getConf();
+        LOG.info("[msx-restart] JournalNode " + this.reconf_msxPort + " stop, double check before stop, " + reconf_parameter + " = " + conf.get(reconf_parameter));
+        synchronized(reconf_point) {
+            if (this.hashCode() == reconf_instanceWithV2HC) {
+                LOG.info("[msx-restart] switch instanceWithV2Alive to false and instanceWithV2HC " + reconf_instanceWithV2HC + " is stopped");
+                reconf_instanceWithV2Alive = false;
+                reconf_instanceWithV2HC = -1;
+            }
+        }
+    } catch (Exception e) {
+        LOG.warn("[msx-restart] " + e.getMessage());
+    }
+
     this.resultCode = rc;
 
     for (JournalNodeSyncer jSyncer : journalSyncersById.values()) {
@@ -312,6 +341,7 @@
   }
   
   public void stopAndJoin(int rc) throws InterruptedException {
+    //System.out.println("[msx-restart] JournalNode stop");
     stop(rc);
     join();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java	2020-03-24 05:28:31.000000000 +0000
@@ -228,6 +228,10 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+// msx
+import java.io.*;
+import org.apache.hadoop.conf.Configured;
+
 /**********************************************************
  * DataNode is a class (and program) that stores a set of
  * blocks for a DFS deployment.  A single deployment can
@@ -419,6 +423,9 @@
   @InterfaceAudience.LimitedPrivate("HDFS")
   DataNode(final Configuration conf) throws DiskErrorException {
     super(conf);
+    // msx
+    performReconf("DataNode", conf);
+
     this.tracer = createTracer(conf);
     this.tracerConfigurationManager =
         new TracerConfigurationManager(DATANODE_HTRACE_PREFIX, conf);
@@ -446,7 +453,10 @@
            final StorageLocationChecker storageLocationChecker,
            final SecureResources resources) throws IOException {
     super(conf);
-    this.tracer = createTracer(conf);
+    // msx
+    performReconf("DataNode", conf);
+   
+     this.tracer = createTracer(conf);
     this.tracerConfigurationManager =
         new TracerConfigurationManager(DATANODE_HTRACE_PREFIX, conf);
     this.fileIoProvider = new FileIoProvider(conf, this);
@@ -1976,6 +1986,20 @@
    * Otherwise, deadlock might occur.
    */
   public void shutdown() {
+    try {
+        Configuration conf = this.getConf();
+        LOG.info("[msx-restart] DataNode " + this.reconf_msxPort + " stop, double check before stop, " + reconf_parameter + " = " + conf.get(reconf_parameter));
+        synchronized(reconf_point) {
+            if (this.hashCode() == reconf_instanceWithV2HC) {
+                LOG.info("[msx-restart] switch instanceWithV2Alive to false and instanceWithV2HC " + reconf_instanceWithV2HC + " is stopped");
+                reconf_instanceWithV2Alive = false;
+                reconf_instanceWithV2HC = -1;
+            }
+        }
+    } catch (Exception e) {
+        LOG.warn("[msx-restart] " + e.getMessage());
+    }
+    
     stopMetricsLogger();
     if (plugins != null) {
       for (ServicePlugin p : plugins) {
@@ -2643,6 +2667,14 @@
     ipcServer.setTracer(tracer);
     ipcServer.start();
     startPlugins(getConf());
+
+    try {
+        this.reconf_msxPort = getIpcPort();
+        Configuration conf = this.getConf();
+        LOG.info("[msx-restart] DataNode " + this.reconf_msxPort + " start, check after start, " + reconf_parameter + " = " + conf.get(reconf_parameter));
+    } catch (Exception e) {
+        LOG.warn("[msx-restart] " + e.getMessage());
+    }
   }
 
   /**
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java	2020-03-24 05:28:31.000000000 +0000
@@ -166,6 +166,10 @@
 import static org.apache.hadoop.fs.CommonConfigurationKeys.IPC_NAMESPACE;
 import static org.apache.hadoop.fs.CommonConfigurationKeys.IPC_BACKOFF_ENABLE_DEFAULT;
 
+// msx
+import java.io.*;
+import org.apache.hadoop.conf.Configured;
+
 /**********************************************************
  * NameNode serves as both directory namespace manager and
  * "inode table" for the Hadoop DFS.  There is a single NameNode
@@ -909,10 +913,14 @@
   public NameNode(Configuration conf) throws IOException {
     this(conf, NamenodeRole.NAMENODE);
   }
-
+  
   protected NameNode(Configuration conf, NamenodeRole role)
       throws IOException {
     super(conf);
+
+    // msx
+    performReconf("NameNode", conf);
+    
     this.tracer = new Tracer.Builder("NameNode").
         conf(TraceUtils.wrapHadoopConf(NAMENODE_HTRACE_PREFIX, conf)).
         build();
@@ -949,6 +957,14 @@
       this.stopAtException(e);
       throw e;
     }
+   
+    try {
+        this.reconf_msxPort = rpcServer.getRpcAddress().getPort();
+        LOG.info("[msx-restart] NameNode " + this.reconf_msxPort + " start, check after start, " + reconf_parameter + " = " + conf.get(reconf_parameter));
+    } catch (Exception e) {
+        LOG.warn("[msx-restart] " + e.getMessage());
+    }
+    
     this.started.set(true);
   }
 
@@ -990,6 +1006,20 @@
    * Stop all NameNode threads and wait for all to finish.
    */
   public void stop() {
+    try {
+        Configuration conf = this.getConf();
+        LOG.info("[msx-restart] NameNode " + this.reconf_msxPort + " stop, double check before stop, " + reconf_parameter + " = " + conf.get(reconf_parameter));
+        synchronized(reconf_point) {
+            if (this.hashCode() == reconf_instanceWithV2HC) {
+                LOG.info("[msx-restart] switch instanceWithV2Alive to false and instanceWithV2HC " + reconf_instanceWithV2HC + " is stopped");
+                reconf_instanceWithV2Alive = false;
+                reconf_instanceWithV2HC = -1;
+            }
+        }
+    } catch (Exception e) {
+        LOG.warn("[msx-restart] " + e.getMessage());
+    }
+
     synchronized(this) {
       if (stopRequested)
         return;
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java	2020-03-24 05:28:31.000000000 +0000
@@ -53,6 +53,7 @@
 
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
+System.out.println("[msx] before_class");
     config = new Configuration();
     config.set("hadoop.security.authorization", "true");
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java	2020-03-24 05:28:31.000000000 +0000
@@ -87,6 +87,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     sockDir = new TemporarySocketDirectory();
     DomainSocket.disableBindPathValidation();
     prevCacheManipulator = NativeIO.POSIX.getCacheManipulator();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java	2020-03-24 05:28:31.000000000 +0000
@@ -47,6 +47,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining()
                                     throws IOException, LoginException, URISyntaxException  {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
     fc = FileContext.getFileContext(cluster.getURI(0), conf);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java	2020-03-24 05:28:31.000000000 +0000
@@ -54,6 +54,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining()
                                     throws IOException, LoginException, URISyntaxException  {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
     fc = FileContext.getFileContext(cluster.getURI(0), conf);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java	2020-03-24 05:28:31.000000000 +0000
@@ -84,6 +84,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining()
         throws IOException, LoginException, URISyntaxException  {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     // set permissions very restrictive
     conf.set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY,  "077");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java	2020-03-24 05:28:31.000000000 +0000
@@ -67,6 +67,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     final Configuration conf = new HdfsConfiguration();
     dfsCluster = new MiniDFSCluster.Builder(conf).build();
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(2).build();
     cluster.waitClusterUp();
     URI uri0 = cluster.getURI(0);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java	2020-03-24 05:28:31.000000000 +0000
@@ -55,6 +55,7 @@
 
   @BeforeClass
   public static void setUp() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     conf.setBoolean(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY, true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSWebHdfsFileContextMainOperations.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSWebHdfsFileContextMainOperations.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSWebHdfsFileContextMainOperations.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSWebHdfsFileContextMainOperations.java	2020-03-24 05:28:31.000000000 +0000
@@ -60,6 +60,7 @@
   @BeforeClass
   public static void clusterSetupAtBeginning()
       throws IOException, LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
 
     File base = new File(BASEDIR);
     FileUtil.fullyDelete(base);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java	2020-03-24 05:28:31.000000000 +0000
@@ -86,6 +86,7 @@
 
   @BeforeClass
   public static void beforeClassSetup() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     conf.set(FsPermission.UMASK_LABEL, "000");
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_MAX_COMPONENT_LENGTH_KEY, 0);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileContext.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileContext.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileContext.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileContext.java	2020-03-24 05:28:31.000000000 +0000
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void testSetup() throws Exception {
+System.out.println("[msx] before_class");
     fc = FileContext.getFileContext(cluster.getURI(0));
     wrapper = new FileContextTestWrapper(fc, "/tmp/TestSymlinkHdfsFileContext");
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java	2020-03-24 05:28:31.000000000 +0000
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void testSetup() throws Exception {
+System.out.println("[msx] before_class");
     wrapper = new FileSystemTestWrapper(dfs, "/tmp/TestSymlinkHdfsFileSystem");
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUrlStreamHandler.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUrlStreamHandler.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUrlStreamHandler.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUrlStreamHandler.java	2020-03-24 05:28:31.000000000 +0000
@@ -50,6 +50,7 @@
 
   @BeforeClass
   public static void setupHandler() {
+System.out.println("[msx] before_class");
 
     // Setup our own factory
     // setURLStreamHandlerFactor is can be set at most once in the JVM
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestWebHdfsFileContextMainOperations.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestWebHdfsFileContextMainOperations.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestWebHdfsFileContextMainOperations.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestWebHdfsFileContextMainOperations.java	2020-03-24 05:28:31.000000000 +0000
@@ -74,6 +74,7 @@
   @BeforeClass
   public static void clusterSetupAtBeginning()
       throws IOException, LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
 
     cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(2).build();
     cluster.waitClusterUp();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractAppend.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractAppend.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractAppend.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractAppend.java	2020-03-24 05:28:31.000000000 +0000
@@ -26,6 +26,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractConcat.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractConcat.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractConcat.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractConcat.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
     // perform a simple operation on the cluster to verify it is up
     HDFSContract.getCluster().getFileSystem().getDefaultBlockSize();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractCreate.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractCreate.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractCreate.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractCreate.java	2020-03-24 05:28:31.000000000 +0000
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractDelete.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractDelete.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractDelete.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractDelete.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractGetFileStatus.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractGetFileStatus.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractGetFileStatus.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractGetFileStatus.java	2020-03-24 05:28:31.000000000 +0000
@@ -31,6 +31,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractMkdir.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractMkdir.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractMkdir.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractMkdir.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractOpen.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractOpen.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractOpen.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractOpen.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java	2020-03-24 05:28:31.000000000 +0000
@@ -40,6 +40,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRename.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRename.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRename.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRename.java	2020-03-24 05:28:31.000000000 +0000
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRootDirectory.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRootDirectory.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRootDirectory.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractRootDirectory.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSeek.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSeek.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSeek.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSeek.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSetTimes.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSetTimes.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSetTimes.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractSetTimes.java	2020-03-24 05:28:31.000000000 +0000
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     HDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java	2020-03-24 05:28:31.000000000 +0000
@@ -68,6 +68,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java	2020-03-24 05:28:31.000000000 +0000
@@ -51,6 +51,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY, true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java	2020-03-24 05:28:31.000000000 +0000
@@ -83,6 +83,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
 
     // Encryption Zone settings
     FileSystemTestHelper fsHelper = new FileSystemTestHelper();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java	2020-03-24 05:28:31.000000000 +0000
@@ -76,6 +76,7 @@
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY,
         true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkMergeSlash.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkMergeSlash.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkMergeSlash.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkMergeSlash.java	2020-03-24 05:28:31.000000000 +0000
@@ -77,6 +77,7 @@
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY,
         true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java	2020-03-24 05:28:31.000000000 +0000
@@ -63,6 +63,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     clusterConf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithTruncate.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithTruncate.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithTruncate.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithTruncate.java	2020-03-24 05:28:31.000000000 +0000
@@ -55,6 +55,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
         .numDataNodes(2).build();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithXAttrs.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithXAttrs.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithXAttrs.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithXAttrs.java	2020-03-24 05:28:31.000000000 +0000
@@ -59,6 +59,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
         .numDataNodes(2)
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java	2020-03-24 05:28:31.000000000 +0000
@@ -52,6 +52,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY, true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java	2020-03-24 05:28:31.000000000 +0000
@@ -77,6 +77,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
 
     CONF.setLong(DFS_BLOCK_SIZE_KEY, DFS_BLOCK_SIZE_DEFAULT);
     CONF.setInt(DFS_BYTES_PER_CHECKSUM_KEY, DFS_BYTES_PER_CHECKSUM_DEFAULT);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java	2020-03-24 05:28:31.000000000 +0000
@@ -62,6 +62,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(2).build();
     cluster.waitClusterUp();
     fHdfs = cluster.getFileSystem();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java	2020-03-24 05:28:31.000000000 +0000
@@ -49,6 +49,7 @@
   @BeforeClass
   public static void clusterSetupAtBegining() throws IOException,
       LoginException, URISyntaxException {
+System.out.println("[msx] before_class");
     SupportsBlocks = true;
     CONF.setBoolean(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_ALWAYS_USE_KEY, true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java	2020-03-24 05:28:31.000000000 +0000
@@ -63,6 +63,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     clusterConf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithXAttrs.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithXAttrs.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithXAttrs.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithXAttrs.java	2020-03-24 05:28:31.000000000 +0000
@@ -58,6 +58,7 @@
 
   @BeforeClass
   public static void clusterSetupAtBeginning() throws IOException {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(clusterConf)
         .nnTopology(MiniDFSNNTopology.simpleFederatedTopology(2))
         .numDataNodes(2)
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/FileAppendTest4.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/FileAppendTest4.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/FileAppendTest4.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/FileAppendTest4.java	2020-03-24 05:28:31.000000000 +0000
@@ -60,6 +60,7 @@
   
   @BeforeClass
   public static void startUp () throws IOException {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     init(conf);
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java	2020-03-24 05:28:31.000000000 +0000
@@ -91,6 +91,7 @@
 
   @BeforeClass
   public static void captureUser() throws IOException {
+System.out.println("[msx] before_class");
     realUgi = UserGroupInformation.getCurrentUser();
     realUser = System.getProperty("user.name");
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java	2020-03-24 05:28:31.000000000 +0000
@@ -46,6 +46,7 @@
 
   @BeforeClass
   public static void setupCluster() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, 4096);
     conf.set("fs.hdfs.impl.disable.cache", "true");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java	2020-03-24 05:28:31.000000000 +0000
@@ -79,6 +79,7 @@
 
   @BeforeClass
   public static void startUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setLong(DFSConfigKeys.DFS_NAMENODE_MIN_BLOCK_SIZE_KEY, BLOCK_SIZE);
     conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY, BLOCK_SIZE);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java	2020-03-24 05:28:31.000000000 +0000
@@ -84,6 +84,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new Configuration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java	2020-03-24 05:28:31.000000000 +0000
@@ -107,6 +107,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     final Configuration conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
     conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, BLOCK_SIZE);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java	2020-03-24 05:28:31.000000000 +0000
@@ -213,6 +213,7 @@
   
   @BeforeClass
   public static void initialize() throws Exception {
+System.out.println("[msx] before_class");
     UpgradeUtilities.initialize();
   }
   
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataStream.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataStream.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataStream.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataStream.java	2020-03-24 05:28:31.000000000 +0000
@@ -37,6 +37,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new Configuration();
     conf.setInt(HdfsClientConfigKeys.DFS_CLIENT_WRITE_PACKET_SIZE_KEY,
         PACKET_SIZE);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeConfig.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeConfig.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeConfig.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeConfig.java	2020-03-24 05:28:31.000000000 +0000
@@ -49,6 +49,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     clearBaseDir();
     Configuration conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_DATANODE_HTTPS_PORT_KEY, 0);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodeBenchmarkThroughput.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodeBenchmarkThroughput.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodeBenchmarkThroughput.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodeBenchmarkThroughput.java	2020-03-24 05:28:31.000000000 +0000
@@ -45,6 +45,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     int numDN = ErasureCodeBenchmarkThroughput.getEcPolicy().getNumDataUnits() +
         ErasureCodeBenchmarkThroughput.getEcPolicy().getNumParityUnits();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java	2020-03-24 05:28:31.000000000 +0000
@@ -67,6 +67,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(conf)
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFetchImage.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFetchImage.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFetchImage.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFetchImage.java	2020-03-24 05:28:31.000000000 +0000
@@ -60,6 +60,7 @@
 
   @BeforeClass
   public static void setupImageDir() {
+System.out.println("[msx] before_class");
     FETCHED_IMAGE_FILE.mkdirs();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java	2020-03-24 05:28:31.000000000 +0000
@@ -73,6 +73,7 @@
 
   @BeforeClass
   public static void setUp() throws java.lang.Exception {
+System.out.println("[msx] before_class");
     AppendTestUtil.LOG.info("setUp()");
     conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY, 512);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java	2020-03-24 05:28:31.000000000 +0000
@@ -65,6 +65,7 @@
   
   @BeforeClass
   public static void testSetUp() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_LIST_LIMIT, 2);
     cluster = new MiniDFSCluster.Builder(conf).build();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSPolicyProvider.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSPolicyProvider.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSPolicyProvider.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSPolicyProvider.java	2020-03-24 05:28:31.000000000 +0000
@@ -76,6 +76,7 @@
 
   @BeforeClass
   public static void initialize() {
+System.out.println("[msx] before_class");
     Service[] services = new HDFSPolicyProvider().getServices();
     policyProviderProtocols = new HashSet<>(services.length);
     for (Service service : services) {
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java	2020-03-24 05:28:31.000000000 +0000
@@ -67,6 +67,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
     fs = FileSystem.get(conf);
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestIsMethodSupported.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestIsMethodSupported.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestIsMethodSupported.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestIsMethodSupported.java	2020-03-24 05:28:31.000000000 +0000
@@ -61,6 +61,7 @@
   
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = (new MiniDFSCluster.Builder(conf))
         .numDataNodes(1).build();
     nnAddress = cluster.getNameNode().getNameNodeAddress();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java	2020-03-24 05:28:31.000000000 +0000
@@ -38,6 +38,7 @@
 
   @BeforeClass
   public static void testSetUp() throws Exception {
+System.out.println("[msx] before_class");
     setTestPaths(new Path("/tmp/TestListFilesInDFS"));
     cluster = new MiniDFSCluster.Builder(conf).build();
     fs = cluster.getFileSystem();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java	2020-03-24 05:28:31.000000000 +0000
@@ -64,6 +64,7 @@
 
   @BeforeClass
   public static void testSetUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new MiniDFSCluster.Builder(conf).build();
     fc = FileContext.getFileContext(cluster.getConfiguration(0));
     fc.delete(TEST_DIR, true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java	2020-03-24 05:28:31.000000000 +0000
@@ -24,6 +24,7 @@
 public class TestParallelRead extends TestParallelReadUtil {
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     // This is a test of the normal (TCP) read path.  For this reason, we turn
     // off both short-circuit local reads and UNIX domain socket data traffic.
     HdfsConfiguration conf = new HdfsConfiguration();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitLegacyRead.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitLegacyRead.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitLegacyRead.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitLegacyRead.java	2020-03-24 05:28:31.000000000 +0000
@@ -26,6 +26,7 @@
 public class TestParallelShortCircuitLegacyRead extends TestParallelReadUtil {
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     DFSInputStream.tcpReadsDisabledForTesting = true;
     HdfsConfiguration conf = new HdfsConfiguration();
     conf.set(DFSConfigKeys.DFS_DOMAIN_SOCKET_PATH_KEY, "");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitRead.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitRead.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitRead.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitRead.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     if (DomainSocket.getLoadingFailureReason() != null) return;
     DFSInputStream.tcpReadsDisabledForTesting = true;
     sockDir = new TemporarySocketDirectory();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadNoChecksum.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadNoChecksum.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadNoChecksum.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadNoChecksum.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     if (DomainSocket.getLoadingFailureReason() != null) return;
     DFSInputStream.tcpReadsDisabledForTesting = true;
     sockDir = new TemporarySocketDirectory();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadUnCached.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadUnCached.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadUnCached.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelShortCircuitReadUnCached.java	2020-03-24 05:28:31.000000000 +0000
@@ -38,6 +38,7 @@
 
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     if (DomainSocket.getLoadingFailureReason() != null) return;
     sockDir = new TemporarySocketDirectory();
     HdfsConfiguration conf = new HdfsConfiguration();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelUnixDomainRead.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelUnixDomainRead.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelUnixDomainRead.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelUnixDomainRead.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   static public void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     if (DomainSocket.getLoadingFailureReason() != null) return;
     DFSInputStream.tcpReadsDisabledForTesting = true;
     sockDir = new TemporarySocketDirectory();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java	2020-03-24 05:28:31.000000000 +0000
@@ -92,6 +92,7 @@
 
   @BeforeClass
   public static void setUpClass() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.set(
         MiniDFSCluster.HDFS_MINIDFS_BASEDIR,
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDNFailure.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDNFailure.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDNFailure.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDNFailure.java	2020-03-24 05:28:31.000000000 +0000
@@ -54,6 +54,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     cluster = initializeCluster();
     dfs = cluster.getFileSystem();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingCorruptData.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingCorruptData.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingCorruptData.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingCorruptData.java	2020-03-24 05:28:31.000000000 +0000
@@ -49,6 +49,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     cluster = initializeCluster();
     dfs = cluster.getFileSystem();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingDeletedData.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingDeletedData.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingDeletedData.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecodingDeletedData.java	2020-03-24 05:28:31.000000000 +0000
@@ -50,6 +50,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     cluster = initializeCluster();
     dfs = cluster.getFileSystem();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java	2020-03-24 05:28:31.000000000 +0000
@@ -134,6 +134,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     baseDir = getTestDir();
     FileUtil.fullyDelete(baseDir);
     assertTrue(baseDir.mkdirs());
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java	2020-03-24 05:28:31.000000000 +0000
@@ -44,6 +44,7 @@
   
   @BeforeClass
   public static void clusterSetUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_SNAPSHOT_MAX_LIMIT, 3);
     cluster = new MiniDFSCluster.Builder(conf).build();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java	2020-03-24 05:28:31.000000000 +0000
@@ -120,6 +120,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     baseDir = getTestDir();
     FileUtil.fullyDelete(baseDir);
     assertTrue(baseDir.mkdirs());
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java	2020-03-24 05:28:31.000000000 +0000
@@ -63,6 +63,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     sockDir = new TemporarySocketDirectory();
     DomainSocket.disableBindPathValidation();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocalLegacy.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocalLegacy.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocalLegacy.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocalLegacy.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
 public class TestBlockReaderLocalLegacy {
   @BeforeClass
   public static void setupCluster() throws IOException {
+System.out.println("[msx] before_class");
     DFSInputStream.tcpReadsDisabledForTesting = true;
     DomainSocket.disableBindPathValidation();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java	2020-03-24 05:28:31.000000000 +0000
@@ -46,6 +46,7 @@
   }
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     final int REPLICATION_FACTOR = 1;
     util = new BlockReaderTestUtil(REPLICATION_FACTOR);
     util.writeFile(TEST_FILE, FILE_SIZE_K);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/crypto/TestHdfsCryptoStreams.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/crypto/TestHdfsCryptoStreams.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/crypto/TestHdfsCryptoStreams.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/crypto/TestHdfsCryptoStreams.java	2020-03-24 05:28:31.000000000 +0000
@@ -45,6 +45,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     dfsCluster = new MiniDFSCluster.Builder(conf).build();
     dfsCluster.waitClusterUp();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java	2020-03-24 05:28:31.000000000 +0000
@@ -85,6 +85,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     racks = new String[NODE_NUM];
     hosts = new String[NODE_NUM];
     types = new StorageType[NODE_NUM];
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferTestCase.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferTestCase.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferTestCase.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferTestCase.java	2020-03-24 05:28:31.000000000 +0000
@@ -77,6 +77,7 @@
 
   @BeforeClass
   public static void initKdc() throws Exception {
+System.out.println("[msx] before_class");
     baseDir = GenericTestUtils
         .getTestDir(SaslDataTransferTestCase.class.getSimpleName());
     FileUtil.fullyDelete(baseDir);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java	2020-03-24 05:28:31.000000000 +0000
@@ -87,6 +87,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     baseDir =
         GenericTestUtils.getTestDir(TestSecureNNWithQJM.class.getSimpleName());
     FileUtil.fullyDelete(baseDir);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java	2020-03-24 05:28:31.000000000 +0000
@@ -97,6 +97,7 @@
   
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     config = new HdfsConfiguration();
     config.setLong(
         DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_MAX_LIFETIME_KEY, 10000);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestAvailableSpaceBlockPlacementPolicy.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestAvailableSpaceBlockPlacementPolicy.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestAvailableSpaceBlockPlacementPolicy.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestAvailableSpaceBlockPlacementPolicy.java	2020-03-24 05:28:31.000000000 +0000
@@ -56,6 +56,7 @@
 
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setFloat(
       DFSConfigKeys.DFS_NAMENODE_AVAILABLE_SPACE_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_PREFERENCE_FRACTION_KEY,
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java	2020-03-24 05:28:31.000000000 +0000
@@ -59,6 +59,7 @@
 
   @BeforeClass
   public static void raiseBlockManagerLogLevels() {
+System.out.println("[msx] before_class");
     GenericTestUtils.setLogLevel(BlockManager.LOG, Level.ALL);
     GenericTestUtils.setLogLevel(BlockReportLeaseManager.LOG, Level.ALL);
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java	2020-03-24 05:28:31.000000000 +0000
@@ -96,6 +96,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_INTERVAL_SECONDS_KEY, 1);
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_CONSIDERLOAD_KEY,
         false);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedStripedBlock.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedStripedBlock.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedStripedBlock.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedStripedBlock.java	2020-03-24 05:28:31.000000000 +0000
@@ -65,6 +65,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     dm = mockDatanodeManager();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
   // allow user with TGT to run tests
   @BeforeClass
   public static void setupKerb() {
+System.out.println("[msx] before_class");
     System.setProperty("java.security.krb5.kdc", "");
     System.setProperty("java.security.krb5.realm", "NONE");
   }    
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java	2020-03-24 05:28:31.000000000 +0000
@@ -58,6 +58,7 @@
 
   @BeforeClass
   public static void setupTest() {
+System.out.println("[msx] before_class");
     EditLogFileOutputStream.setShouldSkipFsyncForTesting(true);
 
     // Track calls to posix_fadvise.
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java	2020-03-24 05:28:31.000000000 +0000
@@ -61,6 +61,7 @@
 
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
+System.out.println("[msx] before_class");
     baseConf = new HdfsConfiguration();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java	2020-03-24 05:28:31.000000000 +0000
@@ -131,6 +131,7 @@
 
   @BeforeClass
   public static void setUpClass() throws Exception {
+System.out.println("[msx] before_class");
     oldInjector = DataNodeFaultInjector.get();
     DataNodeFaultInjector.set(new DataNodeFaultInjector() {
       @Override
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java	2020-03-24 05:28:31.000000000 +0000
@@ -61,6 +61,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     DFSTestUtil.setNameNodeLogLevel(Level.WARN);
     FsDatasetImplTestUtils.setFsDatasetImplLogLevel(Level.WARN);
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     DomainSocket.disableBindPathValidation();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java	2020-03-24 05:28:31.000000000 +0000
@@ -100,6 +100,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new HdfsConfiguration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java	2020-03-24 05:28:31.000000000 +0000
@@ -61,6 +61,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     config = new Configuration();
     if ( DFS_BASE_DIR.exists() && !FileUtil.fullyDelete(DFS_BASE_DIR) ) {
       throw new IOException("Could not delete hdfs directory '" + DFS_BASE_DIR +
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java	2020-03-24 05:28:31.000000000 +0000
@@ -58,6 +58,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
     cluster.waitActive();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDiskspaceQuotaUpdate.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDiskspaceQuotaUpdate.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDiskspaceQuotaUpdate.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDiskspaceQuotaUpdate.java	2020-03-24 05:28:31.000000000 +0000
@@ -70,6 +70,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, BLOCKSIZE);
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION)
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java	2020-03-24 05:28:31.000000000 +0000
@@ -47,6 +47,7 @@
 
   @BeforeClass
   public static void disableFsync() {
+System.out.println("[msx] before_class");
     // No need to fsync for the purposes of tests. This makes
     // the tests run much faster.
     EditLogFileOutputStream.setShouldSkipFsyncForTesting(true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java	2020-03-24 05:28:31.000000000 +0000
@@ -47,6 +47,7 @@
 
   @BeforeClass
   public static void setUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithXAttr.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithXAttr.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithXAttr.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithXAttr.java	2020-03-24 05:28:31.000000000 +0000
@@ -54,6 +54,7 @@
 
   @BeforeClass
   public static void setUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java	2020-03-24 05:28:31.000000000 +0000
@@ -66,6 +66,7 @@
   
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES)
         .build();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java	2020-03-24 05:28:31.000000000 +0000
@@ -37,6 +37,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     startCluster();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java	2020-03-24 05:28:31.000000000 +0000
@@ -35,6 +35,7 @@
 
   @BeforeClass
   public static void setUp() {
+System.out.println("[msx] before_class");
     ExitUtil.disableSystemExit();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeAcl.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeAcl.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeAcl.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeAcl.java	2020-03-24 05:28:31.000000000 +0000
@@ -28,6 +28,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     startCluster();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeHttpServer.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeHttpServer.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeHttpServer.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeHttpServer.java	2020-03-24 05:28:31.000000000 +0000
@@ -66,6 +66,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     File base = new File(BASEDIR);
     FileUtil.fullyDelete(base);
     base.mkdirs();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSecondaryWebUi.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSecondaryWebUi.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSecondaryWebUi.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSecondaryWebUi.java	2020-03-24 05:28:31.000000000 +0000
@@ -41,6 +41,7 @@
   
   @BeforeClass
   public static void setUpCluster() throws IOException {
+System.out.println("[msx] before_class");
     conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,
         "0.0.0.0:0");
     conf.setLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, 500);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSnapshotPathINodes.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSnapshotPathINodes.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSnapshotPathINodes.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSnapshotPathINodes.java	2020-03-24 05:28:31.000000000 +0000
@@ -59,6 +59,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = new Configuration();
     cluster = new MiniDFSCluster.Builder(conf)
       .numDataNodes(REPLICATION)
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java	2020-03-24 05:28:31.000000000 +0000
@@ -79,6 +79,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     initCluster(true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDisallowModifyROSnapshot.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDisallowModifyROSnapshot.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDisallowModifyROSnapshot.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDisallowModifyROSnapshot.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
     cluster.waitActive();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java	2020-03-24 05:28:31.000000000 +0000
@@ -72,6 +72,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);
     initCluster(true);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java	2020-03-24 05:28:31.000000000 +0000
@@ -80,6 +80,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     sockDir = new TemporarySocketDirectory();
     DomainSocket.disableBindPathValidation();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java	2020-03-24 05:28:31.000000000 +0000
@@ -143,6 +143,7 @@
   // multiple tests.
   @BeforeClass
   public static void createOriginalFSImage() throws IOException {
+System.out.println("[msx] before_class");
     File[] nnDirs = MiniDFSCluster.getNameNodeDirectory(
         MiniDFSCluster.getBaseDirectory(), 0, 0);
     tempDir = nnDirs[0];
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForAcl.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForAcl.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForAcl.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForAcl.java	2020-03-24 05:28:31.000000000 +0000
@@ -95,6 +95,7 @@
    */
   @BeforeClass
   public static void createOriginalFSImage() throws IOException {
+System.out.println("[msx] before_class");
     MiniDFSCluster cluster = null;
     try {
       Configuration conf = new Configuration();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java	2020-03-24 05:28:31.000000000 +0000
@@ -61,6 +61,7 @@
    */
   @BeforeClass
   public static void createOriginalFSImage() throws IOException {
+System.out.println("[msx] before_class");
     MiniDFSCluster cluster = null;
     Configuration conf = new Configuration();
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java	2020-03-24 05:28:31.000000000 +0000
@@ -67,6 +67,7 @@
    */
   @BeforeClass
   public static void createOriginalFSImage() throws IOException {
+System.out.println("[msx] before_class");
     MiniDFSCluster cluster = null;
     Configuration conf = new Configuration();
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/FoldedTreeSetTest.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/FoldedTreeSetTest.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/FoldedTreeSetTest.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/FoldedTreeSetTest.java	2020-03-24 05:28:31.000000000 +0000
@@ -43,6 +43,7 @@
 
   @BeforeClass
   public static void setUpClass() {
+System.out.println("[msx] before_class");
     long seed = System.nanoTime();
     System.out.println("This run uses the random seed " + seed);
     srand = new Random(seed);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java	2020-03-24 05:28:31.000000000 +0000
@@ -70,6 +70,7 @@
 
   @BeforeClass
   public static void setupCluster() {
+System.out.println("[msx] before_class");
     final Configuration conf = new Configuration();
     conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, 1024);
     try {
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java	2020-03-24 05:28:31.000000000 +0000
@@ -51,6 +51,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.set(DFSConfigKeys.DFS_HTTP_POLICY_KEY, HttpConfig.Policy.HTTPS_ONLY.name());
     conf.set(DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_KEY, "localhost:0");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSAcl.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSAcl.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSAcl.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSAcl.java	2020-03-24 05:28:31.000000000 +0000
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void init() throws Exception {
+System.out.println("[msx] before_class");
     conf = WebHdfsTestUtil.createConf();
     startCluster();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java	2020-03-24 05:28:31.000000000 +0000
@@ -68,6 +68,7 @@
 
   @BeforeClass
   public static void setUp() {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     SecurityUtil.setAuthenticationMethod(KERBEROS, conf);
     UserGroupInformation.setConfiguration(conf);    
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithAuthenticationFilter.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithAuthenticationFilter.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithAuthenticationFilter.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithAuthenticationFilter.java	2020-03-24 05:28:31.000000000 +0000
@@ -71,6 +71,7 @@
 
   @BeforeClass
   public static void setUp() throws IOException {
+System.out.println("[msx] before_class");
     conf = new Configuration();
     conf.set(DFSConfigKeys.DFS_WEBHDFS_AUTHENTICATION_FILTER_KEY,
         CustomizedFilter.class.getName());
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void setupTest() {
+System.out.println("[msx] before_class");
     setLogLevel();
     try {
       setupCluster(4, 3);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/metrics2/sink/TestRollingFileSystemSinkWithSecureHdfs.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/metrics2/sink/TestRollingFileSystemSinkWithSecureHdfs.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/metrics2/sink/TestRollingFileSystemSinkWithSecureHdfs.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/metrics2/sink/TestRollingFileSystemSinkWithSecureHdfs.java	2020-03-24 05:28:31.000000000 +0000
@@ -79,6 +79,7 @@
    */
   @BeforeClass
   public static void initKdc() throws Exception {
+System.out.println("[msx] before_class");
     Properties kdcConf = MiniKdc.createConf();
     kdc = new MiniKdc(kdcConf, ROOT_TEST_DIR);
     kdc.start();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/security/TestPermissionSymlinks.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/security/TestPermissionSymlinks.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/security/TestPermissionSymlinks.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/security/TestPermissionSymlinks.java	2020-03-24 05:28:31.000000000 +0000
@@ -71,6 +71,7 @@
   
   @BeforeClass
   public static void beforeClassSetUp() throws Exception {
+System.out.println("[msx] before_class");
     conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
     conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);
     conf.set(FsPermission.UMASK_LABEL, "000");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tools/TestTools.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tools/TestTools.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tools/TestTools.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tools/TestTools.java	2020-03-24 05:28:31.000000000 +0000
@@ -43,6 +43,7 @@
 
   @BeforeClass
   public static void before() {
+System.out.println("[msx] before_class");
     ExitUtil.disableSystemExit();
     OPTIONS[1] = INVALID_OPTION;
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java	2020-03-24 05:28:31.000000000 +0000
@@ -52,6 +52,7 @@
 
   @BeforeClass
   public static void init() {
+System.out.println("[msx] before_class");
     sockDir = new TemporarySocketDirectory();
     DomainSocket.disableBindPathValidation();
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/pom.xml ./hadoop-hdfs-project/hadoop-hdfs-client/pom.xml
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/pom.xml	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-client/pom.xml	2020-04-08 03:18:25.427332631 +0000
@@ -34,6 +34,12 @@
   </properties>
 
   <dependencies>
+    <!--<dependency>
+      <groupId>org.apache.hadoop</groupId>
+      <artifactId>hadoop-hdfs</artifactId>
+      <scope>provided</scope>
+      <systemPath>/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-3.1.2.jar</systemPath>
+    </dependency>-->
     <dependency>
       <groupId>com.squareup.okhttp</groupId>
       <artifactId>okhttp</artifactId>
@@ -120,6 +126,14 @@
       <plugin>
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-surefire-plugin</artifactId>
+        <configuration>
+          <properties>
+            <property>
+              <name>listener</name>
+              <value>org.apache.hadoop.test.MyRunListener</value>
+            </property>
+          </properties>
+        </configuration>
       </plugin>
       <plugin>
         <groupId>org.apache.rat</groupId>
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/fs/TestXAttr.java ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/fs/TestXAttr.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/fs/TestXAttr.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/fs/TestXAttr.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
   
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     byte[] value = {0x31, 0x32, 0x33};
     XATTR = new XAttr.Builder()
       .setName("name")
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java	2020-03-24 05:28:31.000000000 +0000
@@ -75,6 +75,7 @@
 
   @BeforeClass
   public static void setupClass() throws Exception {
+System.out.println("[msx] before_class");
     GenericTestUtils.setLogLevel(RequestHedgingProxyProvider.LOG, Level.TRACE);
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java	2020-03-24 05:28:31.000000000 +0000
@@ -63,6 +63,7 @@
 
   @BeforeClass
   public static void setupClass() throws Exception {
+System.out.println("[msx] before_class");
     GenericTestUtils.setLogLevel(RequestHedgingProxyProvider.LOG, Level.TRACE);
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java	2020-03-24 05:28:31.000000000 +0000
@@ -64,6 +64,7 @@
 
   @BeforeClass
   public static void setup() throws IOException {
+System.out.println("[msx] before_class");
     listenSocket = new ServerSocket();
     listenSocket.bind(null);
     bindAddr = NetUtils.getHostPortString(
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml ./hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml	2020-04-08 02:22:53.920054946 +0000
@@ -43,6 +43,14 @@
 
   <dependencies>
     <dependency>
+      <groupId>org.apache.maven.surefire</groupId>
+      <artifactId>surefire-logger-api</artifactId>
+      <version>3.0.0-M4</version>
+      <!-- to get around bug https://github.com/junit-team/junit5/issues/1367 -->
+      <scope>test</scope>
+      <!--<optional>true</optional>-->
+    </dependency>
+    <dependency>
       <groupId>junit</groupId>
       <artifactId>junit</artifactId>
       <scope>test</scope>
@@ -131,7 +139,8 @@
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-hdfs</artifactId>
-      <scope>compile</scope>
+      <scope>provided</scope>
+      <!--<systemPath>/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-3.1.2.jar</systemPath>-->
       <exclusions>
         <exclusion>
           <groupId>commons-cli</groupId>
@@ -254,6 +263,7 @@
       <plugin>
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-surefire-plugin</artifactId>
+	<version>3.0.0-M4</version>
         <configuration>
           <threadCount>1</threadCount>
           <forkedProcessTimeoutInSeconds>600</forkedProcessTimeoutInSeconds>
@@ -264,7 +274,8 @@
           <properties>
             <property>
               <name>listener</name>
-              <value>org.apache.hadoop.test.TimedOutTestsListener</value>
+              <!--<value>org.apache.hadoop.test.TimedOutTestsListener</value>-->
+              <value>org.apache.hadoop.test.MyRunListener</value>
             </property>
           </properties>
           <excludes>
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServerWebServer.java ./hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServerWebServer.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServerWebServer.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServerWebServer.java	2020-03-24 05:28:31.000000000 +0000
@@ -48,6 +48,7 @@
 
   @BeforeClass
   public static void beforeClass() throws Exception {
+System.out.println("[msx] before_class");
     File homeDir = GenericTestUtils.getTestDir();
     File confDir = new File(homeDir, "etc/hadoop");
     File logsDir = new File(homeDir, "logs");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-native-client/pom.xml ./hadoop-hdfs-project/hadoop-hdfs-native-client/pom.xml
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-native-client/pom.xml	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-native-client/pom.xml	2020-04-08 03:20:25.644605624 +0000
@@ -76,6 +76,18 @@
 
   <build>
     <plugins>
+  <plugin>
+    <groupId>org.apache.maven.plugins</groupId>
+    <artifactId>maven-surefire-plugin</artifactId>
+    <configuration>
+      <properties>
+        <property>
+          <name>listener</name>
+          <value>org.apache.hadoop.test.MyRunListener</value>
+        </property>
+      </properties>
+    </configuration>
+  </plugin>
       <plugin>
         <groupId>org.apache.rat</groupId>
         <artifactId>apache-rat-plugin</artifactId>
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/test/TestFuseDFS.java ./hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/test/TestFuseDFS.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/test/TestFuseDFS.java	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/test/TestFuseDFS.java	2020-03-24 05:28:31.000000000 +0000
@@ -234,6 +234,7 @@
 
   @BeforeClass
   public static void startUp() throws IOException {
+System.out.println("[msx] before_class");
     Configuration conf = new HdfsConfiguration();
     r = Runtime.getRuntime();
     mountPoint = System.getProperty("build.test") + "/mnt";
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/pom.xml ./hadoop-hdfs-project/hadoop-hdfs-nfs/pom.xml
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/pom.xml	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-nfs/pom.xml	2020-04-08 03:21:08.641060918 +0000
@@ -53,7 +53,8 @@
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-hdfs</artifactId>
-      <scope>compile</scope>
+      <scope>provided</scope>
+      <!--<systemPath>/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-3.1.2.jar</systemPath>-->
     </dependency>
     <dependency>
       <groupId>org.apache.hadoop</groupId>
@@ -174,7 +175,24 @@
       <scope>test</scope>
     </dependency>
   </dependencies>
-
+ 
+  <build>
+    <plugins>
+    <plugin>
+    <groupId>org.apache.maven.plugins</groupId>
+    <artifactId>maven-surefire-plugin</artifactId>
+    <configuration>
+      <properties>
+        <property>
+          <name>listener</name>
+          <value>org.apache.hadoop.test.MyRunListener</value>
+        </property>
+      </properties>
+    </configuration>
+  </plugin>
+   </plugins>
+  </build>
+ 
   <profiles>
     <profile>
       <id>dist</id>
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestClientAccessPrivilege.java ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestClientAccessPrivilege.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestClientAccessPrivilege.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestClientAccessPrivilege.java	2020-03-24 05:28:31.000000000 +0000
@@ -52,6 +52,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
 
     String currentUser = System.getProperty("user.name");
     config.set(DefaultImpersonationProvider.getTestProvider()
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestNfs3HttpServer.java ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestNfs3HttpServer.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestNfs3HttpServer.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestNfs3HttpServer.java	2020-03-24 05:28:31.000000000 +0000
@@ -45,6 +45,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     conf.set(DFSConfigKeys.DFS_HTTP_POLICY_KEY,
         HttpConfig.Policy.HTTP_AND_HTTPS.name());
     conf.set(NfsConfigKeys.NFS_HTTP_ADDRESS_KEY, "localhost:0");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestReaddir.java ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestReaddir.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestReaddir.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestReaddir.java	2020-03-24 05:28:31.000000000 +0000
@@ -61,6 +61,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
     String currentUser = System.getProperty("user.name");
     config.set(
             DefaultImpersonationProvider.getTestProvider().
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestRpcProgramNfs3.java ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestRpcProgramNfs3.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestRpcProgramNfs3.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestRpcProgramNfs3.java	2020-03-24 05:28:31.000000000 +0000
@@ -123,6 +123,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
     String currentUser = System.getProperty("user.name");
 
     config.set("fs.permissions.umask-mode", "u=rwx,g=,o=");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestViewfsWithNfs3.java ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestViewfsWithNfs3.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestViewfsWithNfs3.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestViewfsWithNfs3.java	2020-03-24 05:28:31.000000000 +0000
@@ -85,6 +85,7 @@
 
   @BeforeClass
   public static void setup() throws Exception {
+System.out.println("[msx] before_class");
     String currentUser = System.getProperty("user.name");
 
     config.set("fs.permissions.umask-mode", "u=rwx,g=,o=");
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/pom.xml ./hadoop-hdfs-project/hadoop-hdfs-rbf/pom.xml
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/pom.xml	2019-01-23 15:07:50.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/pom.xml	2020-04-08 03:21:53.597536967 +0000
@@ -53,6 +53,7 @@
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-hdfs</artifactId>
       <scope>provided</scope>
+      <!--<systemPath>/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-3.1.2.jar</systemPath>-->
     </dependency>
     <dependency>
       <groupId>org.apache.hadoop</groupId>
@@ -111,6 +112,14 @@
       <plugin>
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-surefire-plugin</artifactId>
+        <configuration>
+          <properties>
+            <property>
+              <name>listener</name>
+              <value>org.apache.hadoop.test.MyRunListener</value>
+            </property>
+          </properties>
+    	</configuration>
       </plugin>
       <plugin>
         <groupId>org.apache.maven.plugins</groupId>
@@ -234,4 +243,4 @@
       </plugin>
     </plugins>
   </build>
-</project>
\ No newline at end of file
+</project>
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractAppend.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractAppend.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractAppend.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractAppend.java	2020-03-24 05:28:31.000000000 +0000
@@ -29,6 +29,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractConcat.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractConcat.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractConcat.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractConcat.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
     // perform a simple operation on the cluster to verify it is up
     RouterHDFSContract.getFileSystem().getDefaultBlockSize(new Path("/"));
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractCreate.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractCreate.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractCreate.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractCreate.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractDelete.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractDelete.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractDelete.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractDelete.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractGetFileStatus.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractGetFileStatus.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractGetFileStatus.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractGetFileStatus.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractMkdir.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractMkdir.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractMkdir.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractMkdir.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractOpen.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractOpen.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractOpen.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractOpen.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRename.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRename.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRename.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRename.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRootDirectory.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRootDirectory.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRootDirectory.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractRootDirectory.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSeek.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSeek.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSeek.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSeek.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSetTimes.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSetTimes.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSetTimes.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/TestRouterHDFSContractSetTimes.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractAppend.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractAppend.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractAppend.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractAppend.java	2020-03-24 05:28:31.000000000 +0000
@@ -30,6 +30,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractConcat.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractConcat.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractConcat.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractConcat.java	2020-03-24 05:28:31.000000000 +0000
@@ -35,6 +35,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
     // perform a simple operation on the cluster to verify it is up
     RouterWebHDFSContract.getFileSystem().getDefaultBlockSize(new Path("/"));
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractCreate.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractCreate.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractCreate.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractCreate.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractDelete.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractDelete.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractDelete.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractDelete.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractMkdir.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractMkdir.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractMkdir.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractMkdir.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractOpen.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractOpen.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractOpen.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractOpen.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRename.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRename.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRename.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRename.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRootDirectory.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRootDirectory.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRootDirectory.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractRootDirectory.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractSeek.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractSeek.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractSeek.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/fs/contract/router/web/TestRouterWebHDFSContractSeek.java	2020-03-24 05:28:31.000000000 +0000
@@ -33,6 +33,7 @@
 
   @BeforeClass
   public static void createCluster() throws IOException {
+System.out.println("[msx] before_class");
     RouterWebHDFSContract.createCluster();
   }
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/resolver/TestNamenodeResolver.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/resolver/TestNamenodeResolver.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/resolver/TestNamenodeResolver.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/resolver/TestNamenodeResolver.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void create() throws Exception {
+System.out.println("[msx] before_class");
 
     Configuration conf = getStateStoreConfiguration();
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableNameservices.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableNameservices.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableNameservices.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableNameservices.java	2020-03-24 05:28:31.000000000 +0000
@@ -68,6 +68,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     // Build and start a federated cluster
     cluster = new StateStoreDFSCluster(false, 2);
     Configuration routerConf = new RouterConfigBuilder()
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableRouterQuota.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableRouterQuota.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableRouterQuota.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestDisableRouterQuota.java	2020-03-24 05:28:31.000000000 +0000
@@ -40,6 +40,7 @@
 
   @BeforeClass
   public static void setUp() throws Exception {
+System.out.println("[msx] before_class");
     // Build and start a router
     router = new Router();
     Configuration routerConf = new RouterConfigBuilder()
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouter.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouter.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouter.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouter.java	2020-03-24 05:28:31.000000000 +0000
@@ -51,6 +51,7 @@
 
   @BeforeClass
   public static void create() throws IOException {
+System.out.println("[msx] before_class");
     // Basic configuration without the state store
     conf = new Configuration();
     // 1 sec cache refresh
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java	2020-03-24 05:28:31.000000000 +0000
@@ -82,6 +82,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new StateStoreDFSCluster(false, 1);
     // Build and start a router with State Store + admin + RPC
     Configuration conf = new RouterConfigBuilder()
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdminCLI.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdminCLI.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdminCLI.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdminCLI.java	2020-03-24 05:28:31.000000000 +0000
@@ -76,6 +76,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new StateStoreDFSCluster(false, 1);
     // Build and start a router with State Store + admin + RPC
     Configuration conf = new RouterConfigBuilder()
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java	2020-03-24 05:28:31.000000000 +0000
@@ -62,6 +62,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
 
     // Build and start a federated cluster
     cluster = new StateStoreDFSCluster(false, 1);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterNamenodeHeartbeat.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterNamenodeHeartbeat.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterNamenodeHeartbeat.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterNamenodeHeartbeat.java	2020-03-24 05:28:31.000000000 +0000
@@ -53,6 +53,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
 
     cluster = new MiniRouterDFSCluster(true, 2);
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java	2020-03-24 05:28:31.000000000 +0000
@@ -161,6 +161,7 @@
 
   @BeforeClass
   public static void globalSetUp() throws Exception {
+System.out.println("[msx] before_class");
     cluster = new MiniRouterDFSCluster(false, 2);
     // We need 6 DNs to test Erasure Coding with RS-6-3-64k
     cluster.setNumDatanodesPerNameservice(6);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterSafemode.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterSafemode.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterSafemode.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterSafemode.java	2020-03-24 05:28:31.000000000 +0000
@@ -56,6 +56,7 @@
 
   @BeforeClass
   public static void create() throws IOException {
+System.out.println("[msx] before_class");
     // Wipe state store
     deleteStateStore();
     // Configuration that supports the state store
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreBase.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreBase.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreBase.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreBase.java	2020-03-24 05:28:31.000000000 +0000
@@ -50,6 +50,7 @@
 
   @BeforeClass
   public static void createBase() throws IOException, InterruptedException {
+System.out.println("[msx] before_class");
 
     conf = getStateStoreConfiguration();
 
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMembershipState.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMembershipState.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMembershipState.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMembershipState.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void create() {
+System.out.println("[msx] before_class");
     // Reduce expirations to 5 seconds
     getConf().setLong(
         RBFConfigKeys.FEDERATION_STORE_MEMBERSHIP_EXPIRATION_MS,
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMountTable.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMountTable.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMountTable.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreMountTable.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void create() throws IOException {
+System.out.println("[msx] before_class");
     nameservices = new ArrayList<>();
     nameservices.add(NAMESERVICES[0]);
     nameservices.add(NAMESERVICES[1]);
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreRouterState.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreRouterState.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreRouterState.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/TestStateStoreRouterState.java	2020-03-24 05:28:31.000000000 +0000
@@ -50,6 +50,7 @@
 
   @BeforeClass
   public static void create() {
+System.out.println("[msx] before_class");
     // Reduce expirations to 5 seconds
     getConf().setTimeDuration(
         RBFConfigKeys.FEDERATION_STORE_ROUTER_EXPIRATION_MS,
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFile.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFile.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFile.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFile.java	2020-03-24 05:28:31.000000000 +0000
@@ -34,6 +34,7 @@
 
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = getStateStoreConfiguration(StateStoreFileImpl.class);
     getStateStore(conf);
   }
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFileSystem.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFileSystem.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFileSystem.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreFileSystem.java	2020-03-24 05:28:31.000000000 +0000
@@ -37,6 +37,7 @@
 
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     Configuration conf = FederationStateStoreTestUtils
         .getStateStoreConfiguration(StateStoreFileSystemImpl.class);
     conf.set(StateStoreFileSystemImpl.FEDERATION_STORE_FS_PATH,
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreZK.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreZK.java
--- /hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreZK.java	2019-01-23 15:07:46.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/store/driver/TestStateStoreZK.java	2020-03-24 05:28:31.000000000 +0000
@@ -57,6 +57,7 @@
 
   @BeforeClass
   public static void setupCluster() throws Exception {
+System.out.println("[msx] before_class");
     curatorTestingServer = new TestingServer();
     curatorTestingServer.start();
     String connectString = curatorTestingServer.getConnectString();
diff -ruN /hadoop-3.1.2-src/hadoop-hdfs-project/run_test.sh ./hadoop-hdfs-project/run_test.sh
--- /hadoop-3.1.2-src/hadoop-hdfs-project/run_test.sh	1970-01-01 00:00:00.000000000 +0000
+++ ./hadoop-hdfs-project/run_test.sh	2020-03-24 05:28:31.000000000 +0000
@@ -0,0 +1,10 @@
+#!/bin/bash
+
+for i in hadoop-hdfs-rbf hadoop-hdfs-native-client hadoop-hdfs hadoop-hdfs-nfs hadoop-hdfs-httpfs hadoop-hdfs-client
+do
+    cd ~/hadoop-3.1.2-src/hadoop-hdfs-project/$i
+    pwd
+    mvn test > $i.test_meta_run.txt
+    echo finished for $i
+    sleep 10
+done
